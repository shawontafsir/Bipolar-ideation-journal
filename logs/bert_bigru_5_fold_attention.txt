BiGRU with Attention:
Fold 1/5
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 1: Epoch 1/300: 100%|████████████████████████████████| 2011/2011 [00:26<00:00, 75.88it/s, lr=1e-6, train_loss=0.73]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.05it/s]
Accuracy: 0.535869700360562
F1 score: 0.696627387240959
Precision score: 0.5355491690616019
Recall score: 0.9962807996280799
Train and validation losses: 0.6906091927711434, 0.6876077089110615
=> Saving checkpoint
Fold 1: Epoch 2/300: 100%|███████████████████████████████| 2011/2011 [00:27<00:00, 72.92it/s, lr=1e-6, train_loss=0.693]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.75it/s]
Accuracy: 0.5490488623647892
F1 score: 0.6972201352366642
Precision score: 0.5439624853458382
Recall score: 0.9707112970711297
Train and validation losses: 0.6862751412960737, 0.6816065457184793
=> Saving checkpoint
Fold 1: Epoch 3/300: 100%|███████████████████████████████| 2011/2011 [00:27<00:00, 74.40it/s, lr=1e-6, train_loss=0.687]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.56it/s]
Accuracy: 0.6150690041029466
F1 score: 0.6999418491955806
Precision score: 0.6002327127659575
Recall score: 0.8393770339377034
Train and validation losses: 0.6774253160250477, 0.6666413589452891
=> Saving checkpoint
Fold 1: Epoch 4/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 76.81it/s, lr=1e-6, train_loss=0.671]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.81it/s]
Accuracy: 0.7134153922665672
F1 score: 0.737381793323459
Precision score: 0.7231284916201117
Recall score: 0.7522082752208276
Train and validation losses: 0.655346243254644, 0.6332923115840252
=> Saving checkpoint
Fold 1: Epoch 5/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 75.32it/s, lr=1e-6, train_loss=0.587]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.75it/s]
Accuracy: 0.7760785776451573
F1 score: 0.7828812537673298
Precision score: 0.8131730528424743
Recall score: 0.7547652254765226
Train and validation losses: 0.613863142597207, 0.5762387772440674
=> Saving checkpoint
Fold 1: Epoch 6/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 76.52it/s, lr=1e-6, train_loss=0.577]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.21it/s]
Accuracy: 0.8458286708939451
F1 score: 0.8532544378698225
Precision score: 0.8690935390549662
Recall score: 0.8379823337982334
Train and validation losses: 0.5424898858244652, 0.4761289717188886
=> Saving checkpoint
Fold 1: Epoch 7/300: 100%|████████████████████████████████| 2011/2011 [00:26<00:00, 75.47it/s, lr=1e-6, train_loss=0.28]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.46it/s]
Accuracy: 0.9169464130299639
F1 score: 0.9255959010915571
Precision score: 0.8885799828913601
Recall score: 0.9658298465829847
Train and validation losses: 0.41675567900375726, 0.31549098975141765
=> Saving checkpoint
Fold 1: Epoch 8/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 75.98it/s, lr=1e-6, train_loss=0.154]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.65it/s]
Accuracy: 0.9350988437150317
F1 score: 0.9417540727516179
Precision score: 0.9055793991416309
Recall score: 0.9809390980939098
Train and validation losses: 0.2652012625424824, 0.19780804663452192
=> Saving checkpoint
Fold 1: Epoch 9/300: 100%|██████████████████████████████| 2011/2011 [00:24<00:00, 80.86it/s, lr=1e-6, train_loss=0.0278]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.83it/s]
Accuracy: 0.9449210493596917
F1 score: 0.9499378460843033
Precision score: 0.9243457224543655
Recall score: 0.9769874476987448
Train and validation losses: 0.18210913025005757, 0.1520712988425202
=> Saving checkpoint
Fold 1: Epoch 10/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 73.32it/s, lr=1e-6, train_loss=0.248]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 436.53it/s]
Accuracy: 0.9531269426830784
F1 score: 0.9570663933492769
Precision score: 0.9381558383567761
Recall score: 0.9767549976754998
Train and validation losses: 0.14662693369594573, 0.1304153592249834
=> Saving checkpoint
Fold 1: Epoch 11/300: 100%|██████████████████████████████| 2011/2011 [00:25<00:00, 80.19it/s, lr=1e-6, train_loss=0.303]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.55it/s]
Accuracy: 0.9572298893447718
F1 score: 0.960514233241506
Precision score: 0.9487528344671202
Recall score: 0.9725708972570897
Train and validation losses: 0.1272203066242254, 0.11825958436454978
=> Saving checkpoint
Fold 1: Epoch 12/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.83it/s, lr=1e-6, train_loss=0.339]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.79it/s]
Accuracy: 0.9599651871192341
F1 score: 0.9629629629629629
Precision score: 0.9530965391621129
Recall score: 0.9730357973035797
Train and validation losses: 0.11631909577145409, 0.11064676052722228
=> Saving checkpoint
Fold 1: Epoch 13/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 73.33it/s, lr=1e-6, train_loss=0.194]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.35it/s]
Accuracy: 0.9615814994405073
F1 score: 0.9643557503748991
Precision score: 0.9571788413098237
Recall score: 0.9716410971641097
Train and validation losses: 0.10865400722880178, 0.10549767109219199
=> Saving checkpoint
Fold 1: Epoch 14/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.90it/s, lr=1e-6, train_loss=0.0644]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.41it/s]
Accuracy: 0.9620788263085913
F1 score: 0.9647521090951116
Precision score: 0.9593196966214663
Recall score: 0.9702463970246397
Train and validation losses: 0.10290807870497778, 0.10187755737946208
=> Saving checkpoint
Fold 1: Epoch 15/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 74.12it/s, lr=1e-6, train_loss=0.0174]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.01it/s]
Accuracy: 0.9625761531766753
F1 score: 0.9651902393893836
Precision score: 0.9604142692750288
Recall score: 0.9700139470013946
Train and validation losses: 0.09905134226507653, 0.09894513432491964
=> Saving checkpoint
Fold 1: Epoch 16/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 74.62it/s, lr=1e-6, train_loss=0.19]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.22it/s]
Accuracy: 0.9638194703468855
F1 score: 0.9662921348314607
Precision score: 0.9630570307088432
Recall score: 0.9695490469549047
Train and validation losses: 0.09546147822506619, 0.0966077156838911
=> Saving checkpoint
Fold 1: Epoch 17/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 74.75it/s, lr=1e-6, train_loss=0.0127]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.99it/s]
Accuracy: 0.9646897923660326
F1 score: 0.9671067871206857
Precision score: 0.9637580794090489
Recall score: 0.9704788470478847
Train and validation losses: 0.09263539700472495, 0.0945675231916293
=> Saving checkpoint
Fold 1: Epoch 18/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 76.03it/s, lr=1e-6, train_loss=0.0952]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.50it/s]
Accuracy: 0.9648141240830536
F1 score: 0.9671731817654564
Precision score: 0.9652697383653623
Recall score: 0.9690841469084147
Train and validation losses: 0.08961761636719244, 0.09298666359932638
=> Saving checkpoint
Fold 1: Epoch 19/300: 100%|█████████████████████████████| 2011/2011 [00:25<00:00, 78.59it/s, lr=1e-6, train_loss=0.0252]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.74it/s]
Accuracy: 0.9655601143851796
F1 score: 0.9678393126668988
Precision score: 0.9668290419856181
Recall score: 0.9688516968851697
Train and validation losses: 0.08763490575757053, 0.09153159638583497
=> Saving checkpoint
Fold 1: Epoch 20/300: 100%|█████████████████████████████| 2011/2011 [00:24<00:00, 83.71it/s, lr=1e-6, train_loss=0.0212]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.97it/s]
Accuracy: 0.9656844461022007
F1 score: 0.9679442508710802
Precision score: 0.9672701949860725
Recall score: 0.9686192468619247
Train and validation losses: 0.08641817887239103, 0.09026669052236938
=> Saving checkpoint
Fold 1: Epoch 21/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 71.97it/s, lr=1e-6, train_loss=0.148]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.22it/s]
Accuracy: 0.9668034315553897
F1 score: 0.96897152818129
Precision score: 0.9688589356263072
Recall score: 0.9690841469084147
Train and validation losses: 0.08381794432913565, 0.08910359940945244
=> Saving checkpoint
Fold 1: Epoch 22/300: 100%|█████████████████████████████| 2011/2011 [00:25<00:00, 78.16it/s, lr=1e-6, train_loss=0.0351]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 438.70it/s]
Accuracy: 0.9666790998383687
F1 score: 0.968822708236389
Precision score: 0.9697251979506288
Recall score: 0.9679218967921897
Train and validation losses: 0.08237848336500876, 0.08811065651361588
=> Saving checkpoint
Fold 1: Epoch 23/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.13it/s, lr=1e-6, train_loss=0.0201]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 438.01it/s]
Accuracy: 0.968419743876663
F1 score: 0.9705199628597957
Precision score: 0.969170143718127
Recall score: 0.9718735471873547
Train and validation losses: 0.07960804738092765, 0.08667264974150236
=> Saving checkpoint
Fold 1: Epoch 24/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 76.99it/s, lr=1e-6, train_loss=0.166]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.46it/s]
Accuracy: 0.9685440755936839
F1 score: 0.9706189757287191
Precision score: 0.9698305871431887
Recall score: 0.9714086471408647
Train and validation losses: 0.07898752228287431, 0.08570504134472748
=> Saving checkpoint
Fold 1: Epoch 25/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.23it/s, lr=1e-6, train_loss=0.00261]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 428.86it/s]
Accuracy: 0.968419743876663
F1 score: 0.9704857076458285
Precision score: 0.9702602230483272
Recall score: 0.9707112970711297
Train and validation losses: 0.07690585795433359, 0.08470967121859253
=> Saving checkpoint
Fold 1: Epoch 26/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 77.28it/s, lr=1e-6, train_loss=0.315]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.59it/s]
Accuracy: 0.9685440755936839
F1 score: 0.9705916540741601
Precision score: 0.9707044873285282
Recall score: 0.9704788470478847
Train and validation losses: 0.075488887283713, 0.08386741197393989
=> Saving checkpoint
Fold 1: Epoch 27/300: 100%|██████████████████████████████| 2011/2011 [00:25<00:00, 80.07it/s, lr=1e-6, train_loss=0.079]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.76it/s]
Accuracy: 0.969165734178789
F1 score: 0.9711895910780669
Precision score: 0.9707385044124478
Recall score: 0.9716410971641097
Train and validation losses: 0.07399435005125728, 0.08275908734751254
=> Saving checkpoint
Fold 1: Epoch 28/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.41it/s, lr=1e-6, train_loss=0.00547]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.87it/s]
Accuracy: 0.968917070744747
F1 score: 0.9709167054443928
Precision score: 0.971821145784816
Recall score: 0.9700139470013946
Train and validation losses: 0.07280347424847353, 0.08234504147369792
=> Saving checkpoint
Fold 1: Epoch 29/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.59it/s, lr=1e-6, train_loss=0.164]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.03it/s]
Accuracy: 0.96929006589581
F1 score: 0.9713090951330003
Precision score: 0.9707452983515208
Recall score: 0.9718735471873547
Train and validation losses: 0.07115773229131754, 0.08105778770019517
=> Saving checkpoint
Fold 1: Epoch 30/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.59it/s, lr=1e-6, train_loss=0.00314]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.94it/s]
Accuracy: 0.969414397612831
F1 score: 0.9714152916569835
Precision score: 0.9711895910780669
Recall score: 0.9716410971641097
Train and validation losses: 0.07021760199846971, 0.08026034809337933
=> Saving checkpoint
Fold 1: Epoch 31/300: 100%|█████████████████████████████| 2011/2011 [00:25<00:00, 79.18it/s, lr=1e-6, train_loss=0.0294]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.78it/s]
Accuracy: 0.9699117244809151
F1 score: 0.9718931475029036
Precision score: 0.9712163416898792
Recall score: 0.9725708972570897
Train and validation losses: 0.06901937283693398, 0.07942501918244255
=> Saving checkpoint
Fold 1: Epoch 32/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 80.12it/s, lr=1e-6, train_loss=0.00551]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 427.58it/s]
Accuracy: 0.9700360561979361
F1 score: 0.9719734852889871
Precision score: 0.9725389806841983
Recall score: 0.9714086471408647
Train and validation losses: 0.06702397052073145, 0.07880379629176051
=> Saving checkpoint
Fold 1: Epoch 33/300: 100%|████████████████████████████| 2011/2011 [00:24<00:00, 80.76it/s, lr=1e-6, train_loss=0.00848]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 438.10it/s]
Accuracy: 0.9711550416511252
F1 score: 0.9730796008354606
Precision score: 0.9715013901760889
Recall score: 0.9746629474662948
Train and validation losses: 0.06566579729119017, 0.07794336267056362
=> Saving checkpoint
Fold 1: Epoch 34/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 74.15it/s, lr=1e-6, train_loss=0.0169]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 436.22it/s]
Accuracy: 0.9712793733681462
F1 score: 0.9731113956466069
Precision score: 0.9745861506178597
Recall score: 0.9716410971641097
Train and validation losses: 0.0638914049261151, 0.07754601133481838
=> Saving checkpoint
Fold 1: Epoch 35/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.25it/s, lr=1e-6, train_loss=0.00206]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.65it/s]
Accuracy: 0.9714037050851673
F1 score: 0.9732122059166084
Precision score: 0.9752567693744164
Recall score: 0.9711761971176197
Train and validation losses: 0.06317061048928668, 0.07690201198939553
=> Saving checkpoint
Fold 1: Epoch 36/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.07it/s, lr=1e-6, train_loss=0.0113]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.48it/s]
Accuracy: 0.9720253636702723
F1 score: 0.9738524113887275
Precision score: 0.973739251684871
Recall score: 0.9739655973965597
Train and validation losses: 0.06202795259906456, 0.07596414933415319
=> Saving checkpoint
Fold 1: Epoch 37/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.10it/s, lr=1e-6, train_loss=0.00491]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.02it/s]
Accuracy: 0.9715280368021882
F1 score: 0.9733131336674047
Precision score: 0.9759289553634026
Recall score: 0.9707112970711297
Train and validation losses: 0.060761826511434025, 0.07583238186974775
=> Saving checkpoint
Fold 1: Epoch 38/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.58it/s, lr=1e-6, train_loss=0.0137]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.83it/s]
Accuracy: 0.9725226905383564
F1 score: 0.9743053133356586
Precision score: 0.9746452663410096
Recall score: 0.9739655973965597
Train and validation losses: 0.05917722235746591, 0.07468227317318817
=> Saving checkpoint
Fold 1: Epoch 39/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.10it/s, lr=1e-6, train_loss=0.00133]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.44it/s]
Accuracy: 0.9728956856894194
F1 score: 0.9746570564984888
Precision score: 0.9748837209302326
Recall score: 0.9744304974430498
Train and validation losses: 0.057706098992843874, 0.07414341853213151
=> Saving checkpoint
Fold 1: Epoch 40/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 74.08it/s, lr=1e-6, train_loss=0.000772]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.17it/s]
Accuracy: 0.9735173442745244
F1 score: 0.9752584504588222
Precision score: 0.9746923612723474
Recall score: 0.9758251975825197
Train and validation losses: 0.05689412939065488, 0.07352284976942224
=> Saving checkpoint
Fold 1: Epoch 41/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 76.12it/s, lr=1e-6, train_loss=0.287]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.07it/s]
Accuracy: 0.9727713539723983
F1 score: 0.9745141394158036
Precision score: 0.9757632253553951
Recall score: 0.9732682473268247
Train and validation losses: 0.0564823691864127, 0.07312064827280952
=> Saving checkpoint
Fold 1: Epoch 42/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.41it/s, lr=1e-6, train_loss=0.0111]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.31it/s]
Accuracy: 0.9733930125575034
F1 score: 0.9751104908118167
Precision score: 0.9757914338919925
Recall score: 0.9744304974430498
Train and validation losses: 0.054959505704157, 0.07262222745703907
=> Saving checkpoint
Fold 1: Epoch 43/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.83it/s, lr=1e-6, train_loss=0.0406]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.25it/s]
Accuracy: 0.9733930125575034
F1 score: 0.9750815090824406
Precision score: 0.9769015398973402
Recall score: 0.9732682473268247
Train and validation losses: 0.053709577462575264, 0.07234414264413475
=> Saving checkpoint
Fold 1: Epoch 44/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.62it/s, lr=1e-6, train_loss=0.046]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.94it/s]
Accuracy: 0.9736416759915455
F1 score: 0.9753258845437617
Precision score: 0.9766899766899767
Recall score: 0.9739655973965597
Train and validation losses: 0.05324553285342419, 0.07183731134928148
=> Saving checkpoint
Fold 1: Epoch 45/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.07it/s, lr=1e-6, train_loss=0.287]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.91it/s]
Accuracy: 0.9736416759915455
F1 score: 0.9753201396973225
Precision score: 0.9769123134328358
Recall score: 0.9737331473733147
Train and validation losses: 0.05212939002452495, 0.07160001043676978
=> Saving checkpoint
Fold 1: Epoch 46/300: 100%|████████████████████████████| 2011/2011 [00:23<00:00, 84.63it/s, lr=1e-6, train_loss=0.00886]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.59it/s]
Accuracy: 0.9737660077085665
F1 score: 0.9754279725165949
Precision score: 0.9773628938156359
Recall score: 0.9735006973500697
Train and validation losses: 0.050864461800973856, 0.07134790552275952
=> Saving checkpoint
Fold 1: Epoch 47/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 72.87it/s, lr=1e-6, train_loss=0.00185]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.17it/s]
Accuracy: 0.9737660077085665
F1 score: 0.9754279725165949
Precision score: 0.9773628938156359
Recall score: 0.9735006973500697
Train and validation losses: 0.05035977223907722, 0.07110117168976253
=> Saving checkpoint
Fold 1: Epoch 48/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 74.50it/s, lr=1e-6, train_loss=0.00957]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 436.62it/s]
Accuracy: 0.9741390028596295
F1 score: 0.9757688723205965
Precision score: 0.9780476412891173
Recall score: 0.9735006973500697
Train and validation losses: 0.04984959059820151, 0.07094348708681936
=> Saving checkpoint
Fold 1: Epoch 49/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 74.70it/s, lr=1e-6, train_loss=0.176]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.19it/s]
Accuracy: 0.9737660077085665
F1 score: 0.9754222481071636
Precision score: 0.9775858043427504
Recall score: 0.9732682473268247
Train and validation losses: 0.04859601685993581, 0.07071494748241917
=> Saving checkpoint
Fold 1: Epoch 50/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 78.43it/s, lr=1e-6, train_loss=0.00166]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.96it/s]
Accuracy: 0.9740146711426085
F1 score: 0.9756835369400815
Precision score: 0.9767062660144421
Recall score: 0.9746629474662948
Train and validation losses: 0.047508066282662034, 0.07038118844843982
=> Saving checkpoint
Fold 1: Epoch 51/300: 100%|██████████████████████████████| 2011/2011 [00:25<00:00, 78.26it/s, lr=1e-6, train_loss=0.159]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 436.31it/s]
Accuracy: 0.9737660077085665
F1 score: 0.9754279725165949
Precision score: 0.9773628938156359
Recall score: 0.9735006973500697
Train and validation losses: 0.04658006307863955, 0.07037056405266198
=> Saving checkpoint
Fold 1: Epoch 52/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 72.26it/s, lr=1e-6, train_loss=0.00429]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 438.53it/s]
Accuracy: 0.9740146711426085
F1 score: 0.9756608827297077
Precision score: 0.9775962660443407
Recall score: 0.9737331473733147
Train and validation losses: 0.04612511370213186, 0.07025474888757686
=> Saving checkpoint
Fold 1: Epoch 53/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 77.67it/s, lr=1e-6, train_loss=0.00819]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.33it/s]
Accuracy: 0.9741390028596295
F1 score: 0.9757519235252973
Precision score: 0.9787184284377923
Recall score: 0.9728033472803347
Train and validation losses: 0.04574539924978475, 0.07025126391634341
=> Saving checkpoint
Fold 1: Epoch 54/300: 100%|█████████████████████████████| 2011/2011 [00:25<00:00, 77.84it/s, lr=1e-6, train_loss=0.0135]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.36it/s]
Accuracy: 0.9741390028596295
F1 score: 0.9757632253553951
Precision score: 0.9782710280373832
Recall score: 0.9732682473268247
Train and validation losses: 0.044599542678979864, 0.07013002490123944
=> Saving checkpoint
Fold 1: Epoch 55/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.54it/s, lr=1e-6, train_loss=0.0423]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.94it/s]
Accuracy: 0.9743876662936715
F1 score: 0.9759794776119403
Precision score: 0.9791764155357978
Recall score: 0.9728033472803347
Train and validation losses: 0.043451026145196074, 0.07015839863798135
Fold 1: Epoch 56/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.70it/s, lr=1e-6, train_loss=0.0142]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 439.38it/s]
Accuracy: 0.9738903394255874
F1 score: 0.97556434721899
Precision score: 0.9767008387698043
Recall score: 0.9744304974430498
Train and validation losses: 0.042715933895137295, 0.06991809566026631
=> Saving checkpoint
Fold 1: Epoch 57/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 75.05it/s, lr=1e-6, train_loss=0.00305]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.42it/s]
Accuracy: 0.9740146711426085
F1 score: 0.9756891939048505
Precision score: 0.9764842840512223
Recall score: 0.9748953974895398
Train and validation losses: 0.042580895354904835, 0.06979880729578176
=> Saving checkpoint
Fold 1: Epoch 58/300: 100%|█████████████████████████████| 2011/2011 [00:22<00:00, 90.49it/s, lr=1e-6, train_loss=0.0195]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.06it/s]
Accuracy: 0.9745119980106925
F1 score: 0.9761211415259173
Precision score: 0.9782862479570394
Recall score: 0.9739655973965597
Train and validation losses: 0.04186243560810748, 0.06976806235598737
=> Saving checkpoint
Fold 1: Epoch 59/300: 100%|█████████████████████████████| 2011/2011 [00:24<00:00, 81.58it/s, lr=1e-6, train_loss=0.0736]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.13it/s]
Accuracy: 0.9743876662936715
F1 score: 0.9760018639328985
Precision score: 0.9782811770200841
Recall score: 0.9737331473733147
Train and validation losses: 0.04117849627294944, 0.06980990331861141
Fold 1: Epoch 60/300: 100%|█████████████████████████████| 2011/2011 [00:24<00:00, 80.97it/s, lr=1e-6, train_loss=0.0125]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.24it/s]
Accuracy: 0.9743876662936715
F1 score: 0.9759794776119403
Precision score: 0.9791764155357978
Recall score: 0.9728033472803347
Train and validation losses: 0.0407298190588044, 0.06989717584082053
Fold 1: Epoch 61/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 78.84it/s, lr=1e-6, train_loss=0.00183]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.26it/s]
Accuracy: 0.9742633345766505
F1 score: 0.9758937929428205
Precision score: 0.9778296382730455
Recall score: 0.9739655973965597
Train and validation losses: 0.03979829054004302, 0.06975342195226938
=> Saving checkpoint
Fold 1: Epoch 62/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 75.45it/s, lr=1e-6, train_loss=0.00793]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 424.56it/s]
Accuracy: 0.9742633345766505
F1 score: 0.9758994062172547
Precision score: 0.9776067179846046
Recall score: 0.9741980474198048
Train and validation losses: 0.03867071238971602, 0.0697532403904243
=> Saving checkpoint
Fold 1: Epoch 63/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.47it/s, lr=1e-6, train_loss=0.00137]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.92it/s]
Accuracy: 0.9742633345766505
F1 score: 0.9758769374198811
Precision score: 0.9784996494508063
Recall score: 0.9732682473268247
Train and validation losses: 0.038583992284287646, 0.06978417250528426
Fold 1: Epoch 64/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 75.74it/s, lr=1e-6, train_loss=0.00331]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.05it/s]
Accuracy: 0.9743876662936715
F1 score: 0.975990675990676
Precision score: 0.9787283777466106
Recall score: 0.9732682473268247
Train and validation losses: 0.038410025834105216, 0.0698627789664984
Fold 1: Epoch 65/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 79.65it/s, lr=1e-6, train_loss=0.00115]
Evaluating valid dataset of 8043 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.94it/s]
Accuracy: 0.9745119980106925
F1 score: 0.976110010488288
Precision score: 0.9787333489132976
Recall score: 0.9735006973500697
Train and validation losses: 0.03669300012486201, 0.06984038718611096
Early stopping at epoch 65
Fold 1: Train losses per epoch: [0.6906091927711434, 0.6862751412960737, 0.6774253160250477, 0.655346243254644, 0.613863142597207, 0.5424898858244652, 0.41675567900375726, 0.2652012625424824, 0.18210913025005757, 0.14662693369594573, 0.1272203066242254, 0.11631909577145409, 0.10865400722880178, 0.10290807870497778, 0.09905134226507653, 0.09546147822506619, 0.09263539700472495, 0.08961761636719244, 0.08763490575757053, 0.08641817887239103, 0.08381794432913565, 0.08237848336500876, 0.07960804738092765, 0.07898752228287431, 0.07690585795433359, 0.075488887283713, 0.07399435005125728, 0.07280347424847353, 0.07115773229131754, 0.07021760199846971, 0.06901937283693398, 0.06702397052073145, 0.06566579729119017, 0.0638914049261151, 0.06317061048928668, 0.06202795259906456, 0.060761826511434025, 0.05917722235746591, 0.057706098992843874, 0.05689412939065488, 0.0564823691864127, 0.054959505704157, 0.053709577462575264, 0.05324553285342419, 0.05212939002452495, 0.050864461800973856, 0.05035977223907722, 0.04984959059820151, 0.04859601685993581, 0.047508066282662034, 0.04658006307863955, 0.04612511370213186, 0.04574539924978475, 0.044599542678979864, 0.043451026145196074, 0.042715933895137295, 0.042580895354904835, 0.04186243560810748, 0.04117849627294944, 0.0407298190588044, 0.03979829054004302, 0.03867071238971602, 0.038583992284287646, 0.038410025834105216, 0.03669300012486201]
Fold 1: Valid losses per epoch: [0.6876077089110615, 0.6816065457184793, 0.6666413589452891, 0.6332923115840252, 0.5762387772440674, 0.4761289717188886, 0.31549098975141765, 0.19780804663452192, 0.1520712988425202, 0.1304153592249834, 0.11825958436454978, 0.11064676052722228, 0.10549767109219199, 0.10187755737946208, 0.09894513432491964, 0.0966077156838911, 0.0945675231916293, 0.09298666359932638, 0.09153159638583497, 0.09026669052236938, 0.08910359940945244, 0.08811065651361588, 0.08667264974150236, 0.08570504134472748, 0.08470967121859253, 0.08386741197393989, 0.08275908734751254, 0.08234504147369792, 0.08105778770019517, 0.08026034809337933, 0.07942501918244255, 0.07880379629176051, 0.07794336267056362, 0.07754601133481838, 0.07690201198939553, 0.07596414933415319, 0.07583238186974775, 0.07468227317318817, 0.07414341853213151, 0.07352284976942224, 0.07312064827280952, 0.07262222745703907, 0.07234414264413475, 0.07183731134928148, 0.07160001043676978, 0.07134790552275952, 0.07110117168976253, 0.07094348708681936, 0.07071494748241917, 0.07038118844843982, 0.07037056405266198, 0.07025474888757686, 0.07025126391634341, 0.07013002490123944, 0.07015839863798135, 0.06991809566026631, 0.06979880729578176, 0.06976806235598737, 0.06980990331861141, 0.06989717584082053, 0.06975342195226938, 0.0697532403904243, 0.06978417250528426, 0.0698627789664984, 0.06984038718611096]
Fold 2/5
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 2: Epoch 1/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 70.90it/s, lr=1e-6, train_loss=0.621]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 415.08it/s]
Accuracy: 0.5609301168863466
F1 score: 0.6855463531926262
Precision score: 0.5555715935334873
Recall score: 0.8949081608928157
Train and validation losses: 0.6892565588106984, 0.6845321876865258
=> Saving checkpoint
Fold 2: Epoch 2/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 74.57it/s, lr=1e-6, train_loss=0.675]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 420.86it/s]
Accuracy: 0.6088037801541905
F1 score: 0.6946816770186336
Precision score: 0.5962018990504747
Recall score: 0.8321320623110905
Train and validation losses: 0.6814005128309419, 0.6738961317667194
=> Saving checkpoint
Fold 2: Epoch 3/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 75.00it/s, lr=1e-6, train_loss=0.633]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 410.99it/s]
Accuracy: 0.6779408107435961
F1 score: 0.7074107546317216
Precision score: 0.6879806635904196
Recall score: 0.7279702394791909
Train and validation losses: 0.6674689012401321, 0.6536203607413215
=> Saving checkpoint
Fold 2: Epoch 4/300: 100%|███████████████████████████████| 2011/2011 [00:27<00:00, 72.50it/s, lr=1e-6, train_loss=0.606]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 421.33it/s]
Accuracy: 0.7363839840835613
F1 score: 0.7407679139153828
Precision score: 0.781274181067836
Recall score: 0.704254824459428
Train and validation losses: 0.6416150498070093, 0.6185260309613723
=> Saving checkpoint
Fold 2: Epoch 5/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 71.66it/s, lr=1e-6, train_loss=0.572]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 419.09it/s]
Accuracy: 0.7830141755782144
F1 score: 0.779643894431115
Precision score: 0.8532338308457711
Recall score: 0.7177400604510579
Train and validation losses: 0.5988294954088895, 0.5616453650812979
=> Saving checkpoint
Fold 2: Epoch 6/300: 100%|███████████████████████████████| 2011/2011 [00:26<00:00, 75.46it/s, lr=1e-6, train_loss=0.514]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.59it/s]
Accuracy: 0.8316339219099727
F1 score: 0.834716796875
Precision score: 0.8786944230274993
Recall score: 0.7949314112996978
Train and validation losses: 0.5276361447196289, 0.46650473189875336
=> Saving checkpoint
Fold 2: Epoch 7/300: 100%|███████████████████████████████| 2011/2011 [00:27<00:00, 72.29it/s, lr=1e-6, train_loss=0.369]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.36it/s]
Accuracy: 0.90860482467048
F1 score: 0.9173135335808302
Precision score: 0.8886224934612031
Recall score: 0.9479190885840503
Train and validation losses: 0.406328335108003, 0.3159343172198025
=> Saving checkpoint
Fold 2: Epoch 8/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 69.73it/s, lr=1e-6, train_loss=0.158]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.26it/s]
Accuracy: 0.9334742601342949
F1 score: 0.940296841870327
Precision score: 0.9040772532188841
Recall score: 0.979539641943734
Train and validation losses: 0.2611825061894394, 0.20152641935033305
=> Saving checkpoint
Fold 2: Epoch 9/300: 100%|██████████████████████████████| 2011/2011 [00:28<00:00, 70.29it/s, lr=1e-6, train_loss=0.0721]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.21it/s]
Accuracy: 0.9459089778662024
F1 score: 0.9507417053561318
Precision score: 0.9267108167770419
Recall score: 0.9760520809114159
Train and validation losses: 0.17979117942495113, 0.15341174223684292
=> Saving checkpoint
Fold 2: Epoch 10/300: 100%|██████████████████████████████| 2011/2011 [00:29<00:00, 68.32it/s, lr=1e-6, train_loss=0.068]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.55it/s]
Accuracy: 0.951877642377518
F1 score: 0.9557461406518011
Precision score: 0.9403690369036903
Recall score: 0.9716345036038131
Train and validation losses: 0.14299023129029292, 0.13166946535985583
=> Saving checkpoint
Fold 2: Epoch 11/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.46it/s, lr=1e-6, train_loss=0.0187]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.25it/s]
Accuracy: 0.9547376274558568
F1 score: 0.9582855833142333
Precision score: 0.944858757062147
Recall score: 0.9720995117414555
Train and validation losses: 0.12438678266531508, 0.1202030557376253
=> Saving checkpoint
Fold 2: Epoch 12/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.48it/s, lr=1e-6, train_loss=0.233]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 427.50it/s]
Accuracy: 0.9568515294702811
F1 score: 0.9601470081543586
Precision score: 0.9487063095778484
Recall score: 0.9718670076726342
Train and validation losses: 0.11362260524628101, 0.11338937855797782
=> Saving checkpoint
Fold 2: Epoch 13/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.17it/s, lr=1e-6, train_loss=0.0805]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.78it/s]
Accuracy: 0.958468042775429
F1 score: 0.9615118690942613
Precision score: 0.9531642677633082
Recall score: 0.9700069751220647
Train and validation losses: 0.10727666607839789, 0.10877447585514181
=> Saving checkpoint
Fold 2: Epoch 14/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 74.99it/s, lr=1e-6, train_loss=0.0288]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.45it/s]
Accuracy: 0.9588410843073862
F1 score: 0.9617827040757418
Precision score: 0.9552752293577982
Recall score: 0.9683794466403162
Train and validation losses: 0.10157080550346022, 0.10521941094253782
=> Saving checkpoint
Fold 2: Epoch 15/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.30it/s, lr=1e-6, train_loss=0.0125]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.95it/s]
Accuracy: 0.960084556080577
F1 score: 0.9628343174713442
Precision score: 0.9589483394833949
Recall score: 0.9667519181585678
Train and validation losses: 0.09726450312234303, 0.10273140600269612
=> Saving checkpoint
Fold 2: Epoch 16/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.47it/s, lr=1e-6, train_loss=0.0341]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.71it/s]
Accuracy: 0.9604575976125342
F1 score: 0.9630490355565884
Precision score: 0.9626016260162602
Recall score: 0.9634968611950709
Train and validation losses: 0.09432860252932307, 0.10121415558069292
=> Saving checkpoint
Fold 2: Epoch 17/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.55it/s, lr=1e-6, train_loss=0.0114]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.33it/s]
Accuracy: 0.9613280278537677
F1 score: 0.9638750145196887
Precision score: 0.963091922005571
Recall score: 0.964659381539177
Train and validation losses: 0.09179005164119092, 0.0992972060971362
=> Saving checkpoint
Fold 2: Epoch 18/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 73.02it/s, lr=1e-6, train_loss=0.135]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.02it/s]
Accuracy: 0.961701069385725
F1 score: 0.9642276422764228
Precision score: 0.9633325597586447
Recall score: 0.9651243896768193
Train and validation losses: 0.089715102120279, 0.09790160037830813
=> Saving checkpoint
Fold 2: Epoch 19/300: 100%|██████████████████████████████| 2011/2011 [00:26<00:00, 75.05it/s, lr=1e-6, train_loss=0.334]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 425.52it/s]
Accuracy: 0.9620741109176821
F1 score: 0.9645884128642749
Precision score: 0.9633580705009277
Recall score: 0.965821901883283
Train and validation losses: 0.08810492802477543, 0.09639176369735426
=> Saving checkpoint
Fold 2: Epoch 20/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 71.86it/s, lr=1e-6, train_loss=0.0441]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.13it/s]
Accuracy: 0.9629445411589157
F1 score: 0.965316573556797
Precision score: 0.9664413889536239
Recall score: 0.9641943734015346
Train and validation losses: 0.08561073380039864, 0.09555714420935373
=> Saving checkpoint
Fold 2: Epoch 21/300: 100%|█████████████████████████████| 2011/2011 [00:25<00:00, 78.77it/s, lr=1e-6, train_loss=0.0541]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.95it/s]
Accuracy: 0.9631932355135538
F1 score: 0.9655252737013743
Precision score: 0.9673278879813302
Recall score: 0.9637293652638921
Train and validation losses: 0.0843367729959375, 0.09465390433664721
=> Saving checkpoint
Fold 2: Epoch 22/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 67.44it/s, lr=1e-6, train_loss=0.0317]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 425.54it/s]
Accuracy: 0.9640636657547874
F1 score: 0.9663130901037417
Precision score: 0.968910705937354
Recall score: 0.9637293652638921
Train and validation losses: 0.08274422980248021, 0.09371884407338577
=> Saving checkpoint
Fold 2: Epoch 23/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 68.20it/s, lr=1e-6, train_loss=0.0247]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.01it/s]
Accuracy: 0.9644367072867446
F1 score: 0.966643340331234
Precision score: 0.9698104376316405
Recall score: 0.9634968611950709
Train and validation losses: 0.08139329133759063, 0.09301887875169175
=> Saving checkpoint
Fold 2: Epoch 24/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.33it/s, lr=1e-6, train_loss=0.00382]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.49it/s]
Accuracy: 0.9645610544640637
F1 score: 0.966802562609202
Precision score: 0.9687208216619981
Recall score: 0.9648918856079981
Train and validation losses: 0.07936470989730211, 0.09154597721914307
=> Saving checkpoint
Fold 2: Epoch 25/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.16it/s, lr=1e-6, train_loss=0.0173]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.61it/s]
Accuracy: 0.9645610544640637
F1 score: 0.9667948269835722
Precision score: 0.9689397477814106
Recall score: 0.964659381539177
Train and validation losses: 0.07866460417083793, 0.09065915870102526
=> Saving checkpoint
Fold 2: Epoch 26/300: 100%|██████████████████████████████| 2011/2011 [00:25<00:00, 78.47it/s, lr=1e-6, train_loss=0.234]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.50it/s]
Accuracy: 0.965182790350659
F1 score: 0.9673278879813302
Precision score: 0.9709533848676505
Recall score: 0.9637293652638921
Train and validation losses: 0.077530477490403, 0.09052354142173502
=> Saving checkpoint
Fold 2: Epoch 27/300: 100%|████████████████████████████| 2011/2011 [00:21<00:00, 91.83it/s, lr=1e-6, train_loss=0.00638]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 418.51it/s]
Accuracy: 0.9654314847052972
F1 score: 0.9676217097600746
Precision score: 0.9694282380396733
Recall score: 0.965821901883283
Train and validation losses: 0.07561774097229268, 0.08916641864786758
=> Saving checkpoint
Fold 2: Epoch 28/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.44it/s, lr=1e-6, train_loss=0.00608]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.52it/s]
Accuracy: 0.9659288734145735
F1 score: 0.9680801491146319
Precision score: 0.9701144057903339
Recall score: 0.9660544059521041
Train and validation losses: 0.07437298491341074, 0.08839789846825004
=> Saving checkpoint
Fold 2: Epoch 29/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 72.50it/s, lr=1e-6, train_loss=0.332]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 417.53it/s]
Accuracy: 0.9660532205918926
F1 score: 0.9681706890521161
Precision score: 0.971000935453695
Recall score: 0.9653568937456406
Train and validation losses: 0.07343241398445965, 0.08810278299870063
=> Saving checkpoint
Fold 2: Epoch 30/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.21it/s, lr=1e-6, train_loss=0.0312]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 417.77it/s]
Accuracy: 0.9660532205918926
F1 score: 0.9681781093367525
Precision score: 0.9707807386629266
Recall score: 0.9655893978144617
Train and validation losses: 0.07218555109306785, 0.08698420424688288
=> Saving checkpoint
Fold 2: Epoch 31/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.57it/s, lr=1e-6, train_loss=0.0158]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.84it/s]
Accuracy: 0.9665506093011689
F1 score: 0.968637052582488
Precision score: 0.9714686623012161
Recall score: 0.965821901883283
Train and validation losses: 0.07092883908251196, 0.08625635108169886
=> Saving checkpoint
Fold 2: Epoch 32/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 74.70it/s, lr=1e-6, train_loss=0.00265]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.22it/s]
Accuracy: 0.9660532205918926
F1 score: 0.9682077559100967
Precision score: 0.9699020065328978
Recall score: 0.9665194140897466
Train and validation losses: 0.0694376041317078, 0.08529203942056679
=> Saving checkpoint
Fold 2: Epoch 33/300: 100%|██████████████████████████████| 2011/2011 [00:28<00:00, 69.87it/s, lr=1e-6, train_loss=0.108]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.82it/s]
Accuracy: 0.9664262621238497
F1 score: 0.9685388021440223
Precision score: 0.9708012146694698
Recall score: 0.9662869100209254
Train and validation losses: 0.06900609856747435, 0.08473299992054138
=> Saving checkpoint
Fold 2: Epoch 34/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.12it/s, lr=1e-6, train_loss=0.0213]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.88it/s]
Accuracy: 0.9671723451877643
F1 score: 0.9692164179104478
Precision score: 0.9721637426900585
Recall score: 0.9662869100209254
Train and validation losses: 0.0674765065048642, 0.08437644098246577
=> Saving checkpoint
Fold 2: Epoch 35/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.63it/s, lr=1e-6, train_loss=0.00175]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 416.61it/s]
Accuracy: 0.966923650833126
F1 score: 0.9690121155638397
Precision score: 0.9710483306093859
Recall score: 0.966984422227389
Train and validation losses: 0.06619502592377767, 0.08328396836055024
=> Saving checkpoint
Fold 2: Epoch 36/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 73.76it/s, lr=1e-6, train_loss=0.112]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.45it/s]
Accuracy: 0.9672966923650833
F1 score: 0.9693651718112988
Precision score: 0.9712885154061625
Recall score: 0.9674494303650314
Train and validation losses: 0.06475448255366514, 0.0826238369982075
=> Saving checkpoint
Fold 2: Epoch 37/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.16it/s, lr=1e-6, train_loss=0.0143]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.71it/s]
Accuracy: 0.9679184282516787
F1 score: 0.9699650756693831
Precision score: 0.9713219864770343
Recall score: 0.9686119507091374
Train and validation losses: 0.06391795732584342, 0.08188392142774481
=> Saving checkpoint
Fold 2: Epoch 38/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 72.64it/s, lr=1e-6, train_loss=0.00485]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.08it/s]
Accuracy: 0.9681671226063169
F1 score: 0.9701701235143323
Precision score: 0.9724363466479794
Recall score: 0.9679144385026738
Train and validation losses: 0.06256380261821383, 0.08145302788458142
=> Saving checkpoint
Fold 2: Epoch 39/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 68.86it/s, lr=1e-6, train_loss=0.00258]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 425.68it/s]
Accuracy: 0.968540164138274
F1 score: 0.9705162568465214
Precision score: 0.9728971962616823
Recall score: 0.968146942571495
Train and validation losses: 0.060805586601080944, 0.08078861025474025
=> Saving checkpoint
Fold 2: Epoch 40/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.36it/s, lr=1e-6, train_loss=0.00284]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 427.85it/s]
Accuracy: 0.9689132056702313
F1 score: 0.9708896134140661
Precision score: 0.9724749241894098
Recall score: 0.969309462915601
Train and validation losses: 0.060239865782095024, 0.07989683420958357
=> Saving checkpoint
Fold 2: Epoch 41/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.34it/s, lr=1e-6, train_loss=0.00523]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 419.72it/s]
Accuracy: 0.9691619000248695
F1 score: 0.9711292200232828
Precision score: 0.9724877593844719
Recall score: 0.9697744710532434
Train and validation losses: 0.05903828102734759, 0.07920469404924957
=> Saving checkpoint
Fold 2: Epoch 42/300: 100%|██████████████████████████████| 2011/2011 [00:29<00:00, 68.33it/s, lr=1e-6, train_loss=0.011]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 416.80it/s]
Accuracy: 0.9695349415568266
F1 score: 0.9714817832615528
Precision score: 0.9727272727272728
Recall score: 0.9702394791908858
Train and validation losses: 0.05798017970922629, 0.07852797882393499
=> Saving checkpoint
Fold 2: Epoch 43/300: 100%|██████████████████████████████| 2011/2011 [00:25<00:00, 78.88it/s, lr=1e-6, train_loss=0.172]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.37it/s]
Accuracy: 0.9700323302661029
F1 score: 0.9719343193199022
Precision score: 0.9736350909939337
Recall score: 0.9702394791908858
Train and validation losses: 0.05731333212361753, 0.07800278880737099
=> Saving checkpoint
Fold 2: Epoch 44/300: 100%|███████████████████████████████| 2011/2011 [00:27<00:00, 73.03it/s, lr=1e-6, train_loss=0.04]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.81it/s]
Accuracy: 0.9699079830887839
F1 score: 0.9718080149114632
Precision score: 0.9738501050665421
Recall score: 0.9697744710532434
Train and validation losses: 0.05550883503175516, 0.07757399026855315
=> Saving checkpoint
Fold 2: Epoch 45/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.25it/s, lr=1e-6, train_loss=0.00102]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.40it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9724258289703316
Precision score: 0.9732184443409408
Recall score: 0.9716345036038131
Train and validation losses: 0.05449181382216338, 0.07679641335715667
=> Saving checkpoint
Fold 2: Epoch 46/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.00it/s, lr=1e-6, train_loss=0.00418]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.94it/s]
Accuracy: 0.9709027605073365
F1 score: 0.9727272727272728
Precision score: 0.975227856975929
Recall score: 0.9702394791908858
Train and validation losses: 0.05345584139810696, 0.07642614173797324
=> Saving checkpoint
Fold 2: Epoch 47/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.27it/s, lr=1e-6, train_loss=0.00819]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 418.06it/s]
Accuracy: 0.9712758020392938
F1 score: 0.9730612244897959
Precision score: 0.9761347683668694
Recall score: 0.9700069751220647
Train and validation losses: 0.052279933965380554, 0.07599000900425572
=> Saving checkpoint
Fold 2: Epoch 48/300: 100%|██████████████████████████████| 2011/2011 [00:28<00:00, 69.38it/s, lr=1e-6, train_loss=0.036]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.71it/s]
Accuracy: 0.9720218851032082
F1 score: 0.9737670514165793
Precision score: 0.9766136576239476
Recall score: 0.9709369913973495
Train and validation losses: 0.051645121589741355, 0.07546605983916596
=> Saving checkpoint
Fold 2: Epoch 49/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 69.75it/s, lr=1e-6, train_loss=0.0791]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.32it/s]
Accuracy: 0.9721462322805272
F1 score: 0.9738866868733971
Precision score: 0.9766191255552957
Recall score: 0.9711694954661707
Train and validation losses: 0.05040041404255966, 0.07496964739992933
=> Saving checkpoint
Fold 2: Epoch 50/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 74.22it/s, lr=1e-6, train_loss=0.0155]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.27it/s]
Accuracy: 0.9725192738124845
F1 score: 0.9742754044930741
Precision score: 0.9755244755244755
Recall score: 0.9730295280167403
Train and validation losses: 0.04994839743461783, 0.07428845651188558
=> Saving checkpoint
Fold 2: Epoch 51/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 73.96it/s, lr=1e-6, train_loss=0.055]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 425.00it/s]
Accuracy: 0.9730166625217608
F1 score: 0.9747351263243684
Precision score: 0.9762126865671642
Recall score: 0.9732620320855615
Train and validation losses: 0.048637285873136184, 0.07388696210920832
=> Saving checkpoint
Fold 2: Epoch 52/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.82it/s, lr=1e-6, train_loss=0.00679]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 435.35it/s]
Accuracy: 0.9730166625217608
F1 score: 0.9747174647559128
Precision score: 0.976879962634283
Recall score: 0.9725645198790979
Train and validation losses: 0.04760571666886684, 0.07362526569540462
=> Saving checkpoint
Fold 2: Epoch 53/300: 100%|██████████████████████████████| 2011/2011 [00:29<00:00, 69.21it/s, lr=1e-6, train_loss=0.237]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.40it/s]
Accuracy: 0.9732653568763989
F1 score: 0.9749738098009545
Precision score: 0.9762237762237762
Recall score: 0.9737270402232039
Train and validation losses: 0.04728123032701424, 0.0731844114830299
=> Saving checkpoint
Fold 2: Epoch 54/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.92it/s, lr=1e-6, train_loss=0.0362]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 422.18it/s]
Accuracy: 0.9737627455856752
F1 score: 0.9754165210299429
Precision score: 0.9775805698271836
Recall score: 0.9732620320855615
Train and validation losses: 0.04620141631902544, 0.0729583039733759
=> Saving checkpoint
Fold 2: Epoch 55/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.02it/s, lr=1e-6, train_loss=0.00545]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 428.51it/s]
Accuracy: 0.9730166625217608
F1 score: 0.9747879632856977
Precision score: 0.9742220157919182
Recall score: 0.9753545687049523
Train and validation losses: 0.04501993511800554, 0.07256764857974236
=> Saving checkpoint
Fold 2: Epoch 56/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.08it/s, lr=1e-6, train_loss=0.0494]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 417.41it/s]
Accuracy: 0.9733897040537179
F1 score: 0.9751220646361312
Precision score: 0.9751220646361312
Recall score: 0.9751220646361312
Train and validation losses: 0.04420747454687448, 0.07223452704682738
=> Saving checkpoint
Fold 2: Epoch 57/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.61it/s, lr=1e-6, train_loss=0.00129]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.03it/s]
Accuracy: 0.9733897040537179
F1 score: 0.9751046998604002
Precision score: 0.9757857974388824
Recall score: 0.9744245524296675
Train and validation losses: 0.04352286016797899, 0.0719276471952232
=> Saving checkpoint
Fold 2: Epoch 58/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 72.32it/s, lr=1e-6, train_loss=0.245]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.41it/s]
Accuracy: 0.9731410096990798
F1 score: 0.9748953974895398
Precision score: 0.974668835696026
Recall score: 0.9751220646361312
Train and validation losses: 0.042670670596800846, 0.07172979280596996
=> Saving checkpoint
Fold 2: Epoch 59/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.10it/s, lr=1e-6, train_loss=0.0294]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.62it/s]
Accuracy: 0.9736383984083561
F1 score: 0.9752856143623222
Precision score: 0.978021978021978
Recall score: 0.9725645198790979
Train and validation losses: 0.04207325036697285, 0.0715096812754514
=> Saving checkpoint
Fold 2: Epoch 60/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.97it/s, lr=1e-6, train_loss=0.00329]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 427.13it/s]
Accuracy: 0.9735140512310371
F1 score: 0.9751892836342457
Precision score: 0.9771241830065359
Recall score: 0.9732620320855615
Train and validation losses: 0.04085747710558688, 0.0712421418421774
=> Saving checkpoint
Fold 2: Epoch 61/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.42it/s, lr=1e-6, train_loss=0.00465]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 422.70it/s]
Accuracy: 0.9740114399403134
F1 score: 0.9756665502386774
Precision score: 0.9771455223880597
Recall score: 0.9741920483608463
Train and validation losses: 0.039715419557500256, 0.07098959283507475
=> Saving checkpoint
Fold 2: Epoch 62/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 68.26it/s, lr=1e-6, train_loss=0.00376]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.46it/s]
Accuracy: 0.9740114399403134
F1 score: 0.9756665502386774
Precision score: 0.9771455223880597
Recall score: 0.9741920483608463
Train and validation losses: 0.03951333772323582, 0.07084689784860312
=> Saving checkpoint
Fold 2: Epoch 63/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.16it/s, lr=1e-6, train_loss=0.00164]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 421.39it/s]
Accuracy: 0.9742601342949515
F1 score: 0.975921833197627
Precision score: 0.9764897579143389
Recall score: 0.9753545687049523
Train and validation losses: 0.03820857614932247, 0.07075115962120172
=> Saving checkpoint
Fold 2: Epoch 64/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.07it/s, lr=1e-6, train_loss=0.0646]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.19it/s]
Accuracy: 0.9743844814722705
F1 score: 0.9760687732342007
Precision score: 0.9753889017877874
Recall score: 0.9767495931178796
Train and validation losses: 0.038274421893469024, 0.07073914957076319
=> Saving checkpoint
Fold 2: Epoch 65/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.34it/s, lr=1e-6, train_loss=0.00177]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 436.75it/s]
Accuracy: 0.9743844814722705
F1 score: 0.976046511627907
Precision score: 0.9762735519888346
Recall score: 0.9758195768425948
Train and validation losses: 0.03718759318992733, 0.07053819618423453
=> Saving checkpoint
Fold 2: Epoch 66/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.40it/s, lr=1e-6, train_loss=0.0105]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.09it/s]
Accuracy: 0.9741357871176324
F1 score: 0.9757688723205965
Precision score: 0.9778192855475134
Recall score: 0.9737270402232039
Train and validation losses: 0.036283485237751566, 0.07051128661809683
=> Saving checkpoint
Fold 2: Epoch 67/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.44it/s, lr=1e-6, train_loss=0.00924]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.79it/s]
Accuracy: 0.9742601342949515
F1 score: 0.9759106249272664
Precision score: 0.9769338303821062
Recall score: 0.9748895605673099
Train and validation losses: 0.03570069874532223, 0.07031541870755123
=> Saving checkpoint
Fold 2: Epoch 68/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.39it/s, lr=1e-6, train_loss=0.0126]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.82it/s]
Accuracy: 0.9745088286495897
F1 score: 0.9761821772975485
Precision score: 0.9756154203437064
Recall score: 0.9767495931178796
Train and validation losses: 0.03497825209110128, 0.07044572187735741
Fold 2: Epoch 69/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.71it/s, lr=1e-6, train_loss=0.00279]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 416.39it/s]
Accuracy: 0.9746331758269088
F1 score: 0.9762956077155472
Precision score: 0.9758420441347271
Recall score: 0.9767495931178796
Train and validation losses: 0.03481898148072509, 0.07042116958753966
Fold 2: Epoch 70/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 72.58it/s, lr=1e-6, train_loss=0.00253]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.67it/s]
Accuracy: 0.9746331758269088
F1 score: 0.9763286145277327
Precision score: 0.9745193421357424
Recall score: 0.9781446175308068
Train and validation losses: 0.03334271998623083, 0.07086141259685134
Early stopping at epoch 70
Fold 2: Train losses per epoch: [0.6892565588106984, 0.6814005128309419, 0.6674689012401321, 0.6416150498070093, 0.5988294954088895, 0.5276361447196289, 0.406328335108003, 0.2611825061894394, 0.17979117942495113, 0.14299023129029292, 0.12438678266531508, 0.11362260524628101, 0.10727666607839789, 0.10157080550346022, 0.09726450312234303, 0.09432860252932307, 0.09179005164119092, 0.089715102120279, 0.08810492802477543, 0.08561073380039864, 0.0843367729959375, 0.08274422980248021, 0.08139329133759063, 0.07936470989730211, 0.07866460417083793, 0.077530477490403, 0.07561774097229268, 0.07437298491341074, 0.07343241398445965, 0.07218555109306785, 0.07092883908251196, 0.0694376041317078, 0.06900609856747435, 0.0674765065048642, 0.06619502592377767, 0.06475448255366514, 0.06391795732584342, 0.06256380261821383, 0.060805586601080944, 0.060239865782095024, 0.05903828102734759, 0.05798017970922629, 0.05731333212361753, 0.05550883503175516, 0.05449181382216338, 0.05345584139810696, 0.052279933965380554, 0.051645121589741355, 0.05040041404255966, 0.04994839743461783, 0.048637285873136184, 0.04760571666886684, 0.04728123032701424, 0.04620141631902544, 0.04501993511800554, 0.04420747454687448, 0.04352286016797899, 0.042670670596800846, 0.04207325036697285, 0.04085747710558688, 0.039715419557500256, 0.03951333772323582, 0.03820857614932247, 0.038274421893469024, 0.03718759318992733, 0.036283485237751566, 0.03570069874532223, 0.03497825209110128, 0.03481898148072509, 0.03334271998623083]
Fold 2: Valid losses per epoch: [0.6845321876865258, 0.6738961317667194, 0.6536203607413215, 0.6185260309613723, 0.5616453650812979, 0.46650473189875336, 0.3159343172198025, 0.20152641935033305, 0.15341174223684292, 0.13166946535985583, 0.1202030557376253, 0.11338937855797782, 0.10877447585514181, 0.10521941094253782, 0.10273140600269612, 0.10121415558069292, 0.0992972060971362, 0.09790160037830813, 0.09639176369735426, 0.09555714420935373, 0.09465390433664721, 0.09371884407338577, 0.09301887875169175, 0.09154597721914307, 0.09065915870102526, 0.09052354142173502, 0.08916641864786758, 0.08839789846825004, 0.08810278299870063, 0.08698420424688288, 0.08625635108169886, 0.08529203942056679, 0.08473299992054138, 0.08437644098246577, 0.08328396836055024, 0.0826238369982075, 0.08188392142774481, 0.08145302788458142, 0.08078861025474025, 0.07989683420958357, 0.07920469404924957, 0.07852797882393499, 0.07800278880737099, 0.07757399026855315, 0.07679641335715667, 0.07642614173797324, 0.07599000900425572, 0.07546605983916596, 0.07496964739992933, 0.07428845651188558, 0.07388696210920832, 0.07362526569540462, 0.0731844114830299, 0.0729583039733759, 0.07256764857974236, 0.07223452704682738, 0.0719276471952232, 0.07172979280596996, 0.0715096812754514, 0.0712421418421774, 0.07098959283507475, 0.07084689784860312, 0.07075115962120172, 0.07073914957076319, 0.07053819618423453, 0.07051128661809683, 0.07031541870755123, 0.07044572187735741, 0.07042116958753966, 0.07086141259685134]
Fold 3/5
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 3: Epoch 1/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 70.26it/s, lr=1e-6, train_loss=0.687]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.21it/s]
Accuracy: 0.5467545386719721
F1 score: 0.6971333610303282
Precision score: 0.5424101370571502
Recall score: 0.9753545687049523
Train and validation losses: 0.690217508746877, 0.6839730817802384
=> Saving checkpoint
Fold 3: Epoch 2/300: 100%|███████████████████████████████| 2011/2011 [00:29<00:00, 68.69it/s, lr=1e-6, train_loss=0.686]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 426.17it/s]
Accuracy: 0.6050733648346183
F1 score: 0.6942626107046592
Precision score: 0.5924100542138985
Recall score: 0.838409672169263
Train and validation losses: 0.6808680899993275, 0.6707517374343948
=> Saving checkpoint
Fold 3: Epoch 3/300: 100%|███████████████████████████████| 2011/2011 [00:29<00:00, 68.82it/s, lr=1e-6, train_loss=0.569]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.46it/s]
Accuracy: 0.6963441929868192
F1 score: 0.7174265216385096
Precision score: 0.7141211702372725
Recall score: 0.7207626133457335
Train and validation losses: 0.6626686302658813, 0.6422670054625327
=> Saving checkpoint
Fold 3: Epoch 4/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 70.46it/s, lr=1e-6, train_loss=0.733]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.56it/s]
Accuracy: 0.7653568763989057
F1 score: 0.7643900611811711
Precision score: 0.825512405609493
Recall score: 0.7116949546617066
Train and validation losses: 0.6282369147954682, 0.5952054061899128
=> Saving checkpoint
Fold 3: Epoch 5/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 70.41it/s, lr=1e-6, train_loss=0.513]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.12it/s]
Accuracy: 0.818826162646108
F1 score: 0.820985379039194
Precision score: 0.8705054715997915
Recall score: 0.7767960939316438
Train and validation losses: 0.5723054304844938, 0.5205372277476915
=> Saving checkpoint
Fold 3: Epoch 6/300: 100%|███████████████████████████████| 2011/2011 [00:30<00:00, 66.70it/s, lr=1e-6, train_loss=0.337]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.14it/s]
Accuracy: 0.8946779408107436
F1 score: 0.9030781553953542
Precision score: 0.8891392519152772
Recall score: 0.9174610555684725
Train and validation losses: 0.4747481210382349, 0.3823203627560769
=> Saving checkpoint
Fold 3: Epoch 7/300: 100%|███████████████████████████████| 2011/2011 [00:29<00:00, 68.90it/s, lr=1e-6, train_loss=0.174]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.96it/s]
Accuracy: 0.9220343198209401
F1 score: 0.9304338178187063
Precision score: 0.889855687606112
Recall score: 0.9748895605673099
Train and validation losses: 0.31906933826128087, 0.23863638062067108
=> Saving checkpoint
Fold 3: Epoch 8/300: 100%|███████████████████████████████| 2011/2011 [00:29<00:00, 69.26it/s, lr=1e-6, train_loss=0.213]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 430.98it/s]
Accuracy: 0.9323551355384233
F1 score: 0.9390407888839085
Precision score: 0.9063378758382004
Recall score: 0.9741920483608463
Train and validation losses: 0.21576850828707722, 0.18199130957927667
=> Saving checkpoint
Fold 3: Epoch 9/300: 100%|███████████████████████████████| 2011/2011 [00:28<00:00, 70.44it/s, lr=1e-6, train_loss=0.697]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 432.49it/s]
Accuracy: 0.9414324794827157
F1 score: 0.9466530750934421
Precision score: 0.9229240282685512
Recall score: 0.9716345036038131
Train and validation losses: 0.17217492733071066, 0.15582904812118878
=> Saving checkpoint
Fold 3: Epoch 10/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 74.00it/s, lr=1e-6, train_loss=0.0368]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.88it/s]
Accuracy: 0.9475254911713504
F1 score: 0.9519252677147414
Precision score: 0.9332142059414786
Recall score: 0.9714019995349918
Train and validation losses: 0.14954369796383504, 0.13952123845888534
=> Saving checkpoint
Fold 3: Epoch 11/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.03it/s, lr=1e-6, train_loss=0.0658]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 423.02it/s]
Accuracy: 0.953494155682666
F1 score: 0.9571788413098237
Precision score: 0.9429280397022333
Recall score: 0.9718670076726342
Train and validation losses: 0.13436134333881142, 0.12753333131899358
=> Saving checkpoint
Fold 3: Epoch 12/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.55it/s, lr=1e-6, train_loss=0.0286]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 433.77it/s]
Accuracy: 0.9564784879383238
F1 score: 0.9598163030998852
Precision score: 0.9480607847584487
Recall score: 0.9718670076726342
Train and validation losses: 0.12301114243596481, 0.11797830134178429
=> Saving checkpoint
Fold 3: Epoch 13/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 75.22it/s, lr=1e-6, train_loss=0.0537]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 437.09it/s]
Accuracy: 0.9594628201939815
F1 score: 0.9625975217989904
Precision score: 0.9501698754246886
Recall score: 0.9753545687049523
Train and validation losses: 0.11382983802145784, 0.11044066258341399
=> Saving checkpoint
Fold 3: Epoch 14/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 69.86it/s, lr=1e-6, train_loss=0.0999]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 428.66it/s]
Accuracy: 0.9614523750310868
F1 score: 0.9643923730760395
Precision score: 0.9530079455164586
Recall score: 0.9760520809114159
Train and validation losses: 0.10692454048042005, 0.10437040053082122
=> Saving checkpoint
Fold 3: Epoch 15/300: 100%|█████████████████████████████| 2011/2011 [00:30<00:00, 66.96it/s, lr=1e-6, train_loss=0.0335]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 429.35it/s]
Accuracy: 0.9630688883362347
F1 score: 0.9658424381828637
Precision score: 0.9556213017751479
Recall score: 0.9762845849802372
Train and validation losses: 0.10171212543988593, 0.09923289451520394
=> Saving checkpoint
Fold 3: Epoch 16/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 67.70it/s, lr=1e-6, train_loss=0.0117]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 431.58it/s]
Accuracy: 0.9640636657547874
F1 score: 0.9667089045040894
Precision score: 0.9579908675799087
Recall score: 0.9755870727737735
Train and validation losses: 0.09686774655438826, 0.09550216199022905
=> Saving checkpoint
Fold 3: Epoch 17/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.05it/s, lr=1e-6, train_loss=0.0884]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 425.74it/s]
Accuracy: 0.9654314847052972
F1 score: 0.9679649688868402
Precision score: 0.9595613433858807
Recall score: 0.9765170890490583
Train and validation losses: 0.0939712328187962, 0.09259860274830008
=> Saving checkpoint
Fold 3: Epoch 18/300: 100%|██████████████████████████████| 2011/2011 [00:27<00:00, 71.83it/s, lr=1e-6, train_loss=0.102]
Evaluating valid dataset of 8042 instances: 100%|████████████████████████████████████| 503/503 [00:01<00:00, 434.58it/s]
Accuracy: 0.9663019149465307
F1 score: 0.9687175343414521
Precision score: 0.9619440623567171
Recall score: 0.9755870727737735
Train and validation losses: 0.09149902972982282, 0.09032387249162477
=> Saving checkpoint
Fold 3: Epoch 19/300:  40%|███████████▉                  | 804/2011 [00:10<00:18, 66.38it/s, lr=1e-6, train_loss=0.0277Fold 3: Epoch 19/300:  40%|████████████▍                  | 804/2011 [00:10<00:18, 66.38it/s, lr=1e-6, train_loss=0.198FoldFoFoFold 3: Epoch 19/300:  57%|████████████████▍            | 1141/2011 [00:15<00:09, 91.06it/s, lr=1e-6, train_loss=0.0287]Fold 3: Epoch 19/300:  57%|████████████████▌            | 1151/2011 [00:15<00:09, 91.45it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  58%|█████████████████▎            | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0.Fold 3: Epoch 19/300:  58%|████████████████▋            | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0Fold 3: Epoch 19/300:  58%|█████████████████▉             | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0.44Fold 3: Epoch 19/300:  58%|█████████████████▎            | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0.108Fold 3: Epoch 19/300:  58%|████████████████▋            | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0.0687Fold 3: Epoch 19/300:  58%|█████████████████▎            | 1161/2011 [00:15<00:09, 91.61it/s, lr=1e-6, train_loss=0.393Fold 3: Epoch 19/300:  58%|█████████████████▍            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.393Fold 3: Epoch 19/300:  58%|████████████████▉            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.0765Fold 3: Epoch 19/300:  58%|████████████████▉            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.0265Fold 3: Epoch 19/300:  58%|█████████████████▍            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, trFold 3: Epoch 19/300:  58%|████████████████▎           | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.0089Fold 3: Epoch 19/300:  58%|█████████████████▍            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  58%|████████████████▉            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  58%|████████████████▉            | 1171/2011 [00:15<00:09, 91.66it/s, lr=1e-6, train_loss=0.070Fold 3: Epoch 19/300:  58%|█████████████████▍            | 1171/2011 [00:16<00:09, 91.66it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  58%|████████████████▎           | 1171/2011 [00:16<00:09, 91.66it/s, lr=1e-6, train_loss=0.0099Fold 3: Epoch 19/300:  58%|████████████████▎           | 1171/2011 [00:16<00:09, 91.66it/s, lr=1e-6, train_loss=0.0062Fold 3: Epoch 19/300:  59%|████████████████▍           | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.0062Fold 3: Epoch 19/300:  59%|████████████████▍           | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.0077Fold 3: Epoch 19/300:  59%|█████████████████            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.073Fold 3: Epoch 19/300:  59%|█████████████████▌            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.40Fold 3: Epoch 19/300:  59%|█████████████████▌            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  59%|█████████████████▌            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  59%|█████████████████▌            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  59%|█████████████████            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  59%|█████████████████            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  59%|█████████████████            | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.039Fold 3: Epoch 19/300:  59%|████████████████▍           | 1181/2011 [00:16<00:09, 90.47it/s, lr=1e-6, train_loss=0.0088Fold 3: Epoch 19/300:  59%|████████████████▌           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.0088Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.075Fold 3: Epoch 19/300:  59%|█████████████████▊            | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  59%|████████████████▌           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.0099Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.085Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  59%|█████████████████▏           | 1191/2011 [00:16<00:09, 86.61it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  60%|█████████████████▎           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  60%|████████████████▋           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.0094Fold 3: Epoch 19/300:  60%|████████████████▋           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.0082Fold 3: Epoch 19/300:  60%|█████████████████▉            | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  60%|█████████████████▎           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.050Fold 3: Epoch 19/300:  60%|█████████████████▉            | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  60%|█████████████████▉            | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  60%|█████████████████▉            | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  60%|█████████████████▎           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  60%|█████████████████▎           | 1200/2011 [00:16<00:09, 83.33it/s, lr=1e-6, train_loss=0.062Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.062Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.006Fold 3: Epoch 19/300:  60%|██████████████████            | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.34Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  60%|██████████████████            | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  60%|█████████████████▍           | 1209/2011 [00:16<00:09, 80.24it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  61%|██████████████████▏           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.053Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  61%|██████████████████▏           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.33Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.058Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  61%|█████████████████▌           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  61%|██████████████████▏           | 1218/2011 [00:16<00:10, 77.79it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  61%|██████████████████▎           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  61%|█████████████████▋           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.006Fold 3: Epoch 19/300:  61%|█████████████████           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.0087Fold 3: Epoch 19/300:  61%|█████████████████▋           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.093Fold 3: Epoch 19/300:  61%|██████████████████▎           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  61%|██████████████████▉            | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  61%|█████████████████▋           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  61%|██████████████████▎           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  61%|█████████████████▋           | 1226/2011 [00:16<00:10, 75.14it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  61%|█████████████████▊           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  61%|█████████████████▊           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.039Fold 3: Epoch 19/300:  61%|██████████████████▍           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  61%|██████████████████▍           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.36Fold 3: Epoch 19/300:  61%|█████████████████▊           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  61%|██████████████████▍           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  61%|██████████████████▍           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  61%|██████████████████▍           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  61%|█████████████████▊           | 1234/2011 [00:16<00:10, 72.05it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  62%|██████████████████▌           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  62%|███████████████████▏           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.026Fold 3: Epoch 19/300:  62%|██████████████████▌           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:16<00:10, 70.39it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  62%|█████████████████▉           | 1242/2011 [00:17<00:10, 70.39it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  62%|██████████████████           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  62%|██████████████████▋           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  62%|██████████████████▋           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  62%|██████████████████           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  62%|██████████████████           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  62%|█████████████████▍          | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.0072Fold 3: Epoch 19/300:  62%|██████████████████▋           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  62%|██████████████████▋           | 1250/2011 [00:17<00:11, 68.68it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  63%|██████████████████▊           | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  63%|██████████████████▊           | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.057Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.043Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1257/2011 [00:17<00:11, 67.77it/s, lr=1e-6, train_loss=0.007Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.007Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  63%|███████████████████▍           | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  63%|███████████████████▍           | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  63%|█████████████████▌          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.0063Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  63%|██████████████████▏          | 1264/2011 [00:17<00:11, 67.34it/s, lr=1e-6, train_loss=0.076Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.076Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  63%|██████████████████▉           | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.26Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  63%|██████████████████▎          | 1271/2011 [00:17<00:11, 67.23it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.026Fold 3: Epoch 19/300:  64%|███████████████████           | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.37Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  64%|███████████████████           | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.31Fold 3: Epoch 19/300:  64%|██████████████████▍          | 1278/2011 [00:17<00:10, 67.01it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  64%|██████████████████▌          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  64%|██████████████████▌          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.099Fold 3: Epoch 19/300:  64%|██████████████████▌          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.093Fold 3: Epoch 19/300:  64%|███████████████████▏          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  64%|██████████████████▌          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  64%|███████████████████▏          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  64%|██████████████████▌          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  64%|███████████████████▏          | 1285/2011 [00:17<00:10, 66.99it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  64%|███████████████████▎          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.086Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.090Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  64%|███████████████████▎          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.07Fold 3: Epoch 19/300:  64%|██████████████████▋          | 1292/2011 [00:17<00:10, 67.23it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.092Fold 3: Epoch 19/300:  65%|██████████████████          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.0085Fold 3: Epoch 19/300:  65%|███████████████████▍          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  65%|██████████████████▋          | 1299/2011 [00:17<00:10, 66.01it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  65%|██████████████████▊          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  65%|████████████████████▏          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.3Fold 3: Epoch 19/300:  65%|███████████████████▍          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  65%|██████████████████▊          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  65%|███████████████████▍          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.30Fold 3: Epoch 19/300:  65%|███████████████████▍          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  65%|██████████████████▊          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  65%|██████████████████▊          | 1306/2011 [00:17<00:11, 62.66it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:17<00:10, 64.43it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:17<00:10, 64.43it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:17<00:10, 64.43it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  65%|███████████████████▌          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  65%|███████████████████▌          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  65%|██████████████████▉          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  65%|███████████████████▌          | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  65%|██████████████████▎         | 1313/2011 [00:18<00:10, 64.43it/s, lr=1e-6, train_loss=0.0055Fold 3: Epoch 19/300:  66%|██████████████████▍         | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.0055Fold 3: Epoch 19/300:  66%|███████████████████          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  66%|███████████████████▋          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  66%|███████████████████▋          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  66%|███████████████████▋          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  66%|███████████████████          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  66%|███████████████████▋          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.02Fold 3: Epoch 19/300:  66%|███████████████████          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.049Fold 3: Epoch 19/300:  66%|███████████████████▋          | 1322/2011 [00:18<00:09, 69.83it/s, lr=1e-6, train_loss=0.34Fold 3: Epoch 19/300:  66%|███████████████████▊          | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.34Fold 3: Epoch 19/300:  66%|██████████████████▌         | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.0088Fold 3: Epoch 19/300:  66%|███████████████████▏         | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.073Fold 3: Epoch 19/300:  66%|███████████████████▏         | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  66%|███████████████████▊          | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  66%|███████████████████▊          | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.35Fold 3: Epoch 19/300:  66%|███████████████████▏         | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.022Fold 3: Epoch 19/300:  66%|███████████████████▏         | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  66%|███████████████████▊          | 1330/2011 [00:18<00:09, 71.87it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  67%|███████████████████▉          | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.095Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.059Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.062Fold 3: Epoch 19/300:  67%|███████████████████▉          | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  67%|███████████████████▎         | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  67%|███████████████████▉          | 1338/2011 [00:18<00:09, 71.10it/s, lr=1e-6, train_loss=0.45Fold 3: Epoch 19/300:  67%|████████████████████          | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.45Fold 3: Epoch 19/300:  67%|████████████████████          | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  67%|███████████████████▍         | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  67%|███████████████████▍         | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  67%|███████████████████▍         | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  67%|████████████████████          | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  67%|██████████████████▋         | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.0086Fold 3: Epoch 19/300:  67%|████████████████████          | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  67%|███████████████████▍         | 1346/2011 [00:18<00:09, 71.93it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  67%|███████████████████▌         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.28Fold 3: Epoch 19/300:  67%|███████████████████▌         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.08Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.27Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.07Fold 3: Epoch 19/300:  67%|███████████████████▌         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  67%|████████████████████▏         | 1354/2011 [00:18<00:09, 71.86it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  68%|████████████████████▎         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  68%|████████████████████▎         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.35Fold 3: Epoch 19/300:  68%|████████████████████▎         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.02Fold 3: Epoch 19/300:  68%|██████████████████▉         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.0045Fold 3: Epoch 19/300:  68%|███████████████████▋         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  68%|███████████████████▋         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  68%|███████████████████▋         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  68%|███████████████████▋         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  68%|████████████████████▎         | 1362/2011 [00:18<00:09, 70.12it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  68%|████████████████████▍         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  68%|████████████████████▍         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.27Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.079Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  68%|████████████████████▍         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.30Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.084Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1370/2011 [00:18<00:09, 68.93it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  68%|████████████████████▌         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  68%|█████████████████████▏         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  68%|███████████████████▊         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  68%|████████████████████▌         | 1377/2011 [00:18<00:09, 68.20it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  69%|████████████████████▋         | 1384/2011 [00:18<00:09, 67.65it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  69%|███████████████████▉         | 1384/2011 [00:18<00:09, 67.65it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  69%|███████████████████▉         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  69%|████████████████████▋         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  69%|████████████████████▋         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  69%|███████████████████▉         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.059Fold 3: Epoch 19/300:  69%|███████████████████▉         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  69%|████████████████████▋         | 1384/2011 [00:19<00:09, 67.65it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  69%|████████████████████▊         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  69%|████████████████████         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  69%|████████████████████         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  69%|█████████████████████▍         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.2Fold 3: Epoch 19/300:  69%|████████████████████         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  69%|████████████████████         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  69%|████████████████████▊         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  69%|████████████████████         | 1391/2011 [00:19<00:09, 67.26it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  70%|█████████████████████▌         | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.3Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  70%|████████████████████▏        | 1398/2011 [00:19<00:09, 66.98it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.037Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.080Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  70%|████████████████████▉         | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.47Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.088Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.090Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1405/2011 [00:19<00:09, 66.33it/s, lr=1e-6, train_loss=0.056Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.056Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  70%|█████████████████████         | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.39Fold 3: Epoch 19/300:  70%|█████████████████████         | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  70%|████████████████████▎        | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  70%|█████████████████████         | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  70%|█████████████████████         | 1412/2011 [00:19<00:09, 66.31it/s, lr=1e-6, train_loss=0.24Fold 3: Epoch 19/300:  71%|█████████████████████▏        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.24Fold 3: Epoch 19/300:  71%|████████████████████▍        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  71%|████████████████████▍        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  71%|█████████████████████▏        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.35Fold 3: Epoch 19/300:  71%|█████████████████████▏        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  71%|████████████████████▍        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.083Fold 3: Epoch 19/300:  71%|█████████████████████▏        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  71%|████████████████████▍        | 1419/2011 [00:19<00:09, 64.00it/s, lr=1e-6, train_loss=0.070Fold 3: Epoch 19/300:  71%|████████████████████▌        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.070Fold 3: Epoch 19/300:  71%|█████████████████████▎        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  71%|████████████████████▌        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  71%|█████████████████████▎        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  71%|████████████████████▌        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.057Fold 3: Epoch 19/300:  71%|████████████████████▌        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.091Fold 3: Epoch 19/300:  71%|█████████████████████▎        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  71%|███████████████████▊        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.0053Fold 3: Epoch 19/300:  71%|████████████████████▌        | 1426/2011 [00:19<00:09, 62.54it/s, lr=1e-6, train_loss=0.075Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.075Fold 3: Epoch 19/300:  71%|█████████████████████▍        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.083Fold 3: Epoch 19/300:  71%|█████████████████████▍        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.25Fold 3: Epoch 19/300:  71%|█████████████████████▍        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.03Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.005Fold 3: Epoch 19/300:  71%|█████████████████████▍        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.026Fold 3: Epoch 19/300:  71%|████████████████████▋        | 1434/2011 [00:19<00:08, 66.50it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  72%|█████████████████████▌        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.056Fold 3: Epoch 19/300:  72%|█████████████████████▌        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  72%|█████████████████████▌        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.098Fold 3: Epoch 19/300:  72%|████████████████████▊        | 1443/2011 [00:19<00:08, 70.89it/s, lr=1e-6, train_loss=0.054Fold 3: Epoch 19/300:  72%|████████████████████▉        | 1451/2011 [00:19<00:07, 70.40it/s, lr=1e-6, train_loss=0.054Fold 3: Epoch 19/300:  72%|█████████████████████▋        | 1451/2011 [00:19<00:07, 70.40it/s, lr=1e-6, train_loss=0.46Fold 3: Epoch 19/300:  72%|████████████████████▏       | 1451/2011 [00:19<00:07, 70.40it/s, lr=1e-6, train_loss=0.0068Fold 3: Epoch 19/300:  72%|████████████████████▉        | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  72%|████████████████████▉        | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  72%|███████████████████████         | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.Fold 3: Epoch 19/300:  72%|████████████████████▉        | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  72%|█████████████████████▋        | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  72%|█████████████████████▋        | 1451/2011 [00:20<00:07, 70.40it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  73%|█████████████████████        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.53Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  73%|█████████████████████        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  73%|█████████████████████        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  73%|█████████████████████▊        | 1459/2011 [00:20<00:07, 71.43it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  73%|█████████████████████▏       | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  73%|████████████████████▍       | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.0072Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  73%|█████████████████████▉        | 1467/2011 [00:20<00:07, 71.92it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  73%|██████████████████████        | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  73%|█████████████████████▎       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  73%|████████████████████▌       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.0046Fold 3: Epoch 19/300:  73%|██████████████████████        | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  73%|█████████████████████▎       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  73%|████████████████████▌       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.0094Fold 3: Epoch 19/300:  73%|█████████████████████▎       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  73%|████████████████████▌       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.0041Fold 3: Epoch 19/300:  73%|█████████████████████▎       | 1475/2011 [00:20<00:07, 71.86it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  74%|█████████████████████▍       | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  74%|██████████████████████        | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.25Fold 3: Epoch 19/300:  74%|████████████████████▋       | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.0092Fold 3: Epoch 19/300:  74%|██████████████████████▊        | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  74%|█████████████████████▍       | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  74%|██████████████████████▊        | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  74%|██████████████████████        | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  74%|█████████████████████▍       | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  74%|█████████████████████▍       | 1483/2011 [00:20<00:07, 70.31it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  74%|██████████████████████▏       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  74%|██████████████████████▏       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1491/2011 [00:20<00:07, 68.97it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  74%|██████████████████████▎       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.00Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  74%|██████████████████████▎       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  74%|██████████████████████▎       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  74%|█████████████████████▌       | 1498/2011 [00:20<00:07, 68.24it/s, lr=1e-6, train_loss=0.083Fold 3: Epoch 19/300:  75%|█████████████████████▋       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.083Fold 3: Epoch 19/300:  75%|█████████████████████▋       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  75%|██████████████████████▍       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  75%|█████████████████████▋       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  75%|████████████████████▉       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.0079Fold 3: Epoch 19/300:  75%|██████████████████████▍       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  75%|█████████████████████▋       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  75%|██████████████████████▍       | 1505/2011 [00:20<00:07, 67.62it/s, lr=1e-6, train_loss=0.32Fold 3: Epoch 19/300:  75%|██████████████████████▌       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.32Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  75%|██████████████████████▌       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  75%|█████████████████████▊       | 1512/2011 [00:20<00:07, 67.24it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:20<00:07, 66.86it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:20<00:07, 66.86it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:20<00:07, 66.86it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:21<00:07, 66.86it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:21<00:07, 66.86it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:21<00:07, 66.86it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:21<00:07, 66.86it/s, lr=1e-6, train_loss=0.077Fold 3: Epoch 19/300:  76%|█████████████████████▉       | 1519/2011 [00:21<00:07, 66.86it/s, lr=1e-6, train_loss=0.039Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.039Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.050Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  76%|███████████████████████▌       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.2Fold 3: Epoch 19/300:  76%|██████████████████████       | 1526/2011 [00:21<00:07, 65.44it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.058Fold 3: Epoch 19/300:  76%|████████████████████████▍       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.078Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  76%|██████████████████████▊       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  76%|██████████████████████       | 1533/2011 [00:21<00:07, 65.39it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  77%|██████████████████████▏      | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  77%|███████████████████████▊       | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  77%|██████████████████████▏      | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  77%|██████████████████████▉       | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  77%|██████████████████████▉       | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.37Fold 3: Epoch 19/300:  77%|██████████████████████▏      | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  77%|█████████████████████▍      | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.0036Fold 3: Epoch 19/300:  77%|███████████████████████▊       | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.3Fold 3: Epoch 19/300:  77%|██████████████████████▉       | 1541/2011 [00:21<00:06, 67.95it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  77%|███████████████████████       | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  77%|██████████████████████▎      | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  77%|███████████████████████       | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.08Fold 3: Epoch 19/300:  77%|███████████████████████       | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  77%|██████████████████████▎      | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.052Fold 3: Epoch 19/300:  77%|██████████████████████▎      | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  77%|███████████████████████       | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  77%|██████████████████████▎      | 1549/2011 [00:21<00:06, 69.53it/s, lr=1e-6, train_loss=0.081Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.081Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.022Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  77%|███████████████████████▏      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.48Fold 3: Epoch 19/300:  77%|██████████████████████▍      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  77%|███████████████████████▏      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  77%|███████████████████████▏      | 1556/2011 [00:21<00:06, 66.64it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  78%|██████████████████████▌      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.25Fold 3: Epoch 19/300:  78%|██████████████████████▌      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  78%|█████████████████████▊      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.0067Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  78%|███████████████████████▎      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.08Fold 3: Epoch 19/300:  78%|██████████████████████▌      | 1565/2011 [00:21<00:06, 71.04it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  78%|██████████████████████▋      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  78%|██████████████████████▋      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.31Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  78%|██████████████████████▋      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  78%|███████████████████████▍      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  78%|██████████████████████▋      | 1574/2011 [00:21<00:05, 74.47it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  79%|███████████████████████▌      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  79%|███████████████████████▌      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.02Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  79%|███████████████████████▌      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  79%|███████████████████████▌      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.32Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  79%|██████████████████████▊      | 1583/2011 [00:21<00:05, 77.02it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:21<00:05, 79.01it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:21<00:05, 79.01it/s, lr=1e-6, train_loss=0.009Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:21<00:05, 79.01it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:21<00:05, 79.01it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:21<00:05, 79.01it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  79%|██████████████████████▉      | 1592/2011 [00:22<00:05, 79.01it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  79%|███████████████████████▋      | 1592/2011 [00:22<00:05, 79.01it/s, lr=1e-6, train_loss=0.02Fold 3: Epoch 19/300:  79%|███████████████████████▋      | 1592/2011 [00:22<00:05, 79.01it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  79%|███████████████████████▋      | 1592/2011 [00:22<00:05, 79.01it/s, lr=1e-6, train_loss=0.45Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.45Fold 3: Epoch 19/300:  80%|███████████████████████      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.41Fold 3: Epoch 19/300:  80%|███████████████████████      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  80%|██████████████████████▎     | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.0048Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.36Fold 3: Epoch 19/300:  80%|███████████████████████▊      | 1600/2011 [00:22<00:05, 77.88it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  80%|███████████████████████▉      | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  80%|███████████████████████▏     | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  80%|███████████████████████▉      | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  80%|███████████████████████▉      | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.02Fold 3: Epoch 19/300:  80%|███████████████████████▉      | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  80%|███████████████████████▏     | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  80%|███████████████████████▏     | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  80%|███████████████████████▉      | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  80%|███████████████████████▏     | 1608/2011 [00:22<00:05, 76.21it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  80%|████████████████████████      | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  80%|██████████████████████▌     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.0086Fold 3: Epoch 19/300:  80%|████████████████████████      | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  80%|███████████████████████▎     | 1616/2011 [00:22<00:05, 73.71it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.052Fold 3: Epoch 19/300:  81%|████████████████████████▏     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.24Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.037Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  81%|████████████████████████▏     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  81%|███████████████████████▍     | 1624/2011 [00:22<00:05, 71.38it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  81%|███████████████████████▌     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  81%|██████████████████████▋     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.0094Fold 3: Epoch 19/300:  81%|████████████████████████▎     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  81%|███████████████████████▌     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  81%|████████████████████████▎     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  81%|███████████████████████▌     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.076Fold 3: Epoch 19/300:  81%|███████████████████████▌     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  81%|█████████████████████████▏     | 1632/2011 [00:22<00:05, 69.77it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300:  82%|█████████████████████████▎     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300:  82%|████████████████████████▍     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.33Fold 3: Epoch 19/300:  82%|████████████████████████▍     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  82%|████████████████████████▍     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.074Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1639/2011 [00:22<00:05, 68.58it/s, lr=1e-6, train_loss=0.050Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.050Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.080Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  82%|██████████████████████▉     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.0079Fold 3: Epoch 19/300:  82%|███████████████████████▋     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.086Fold 3: Epoch 19/300:  82%|████████████████████████▌     | 1646/2011 [00:22<00:05, 67.16it/s, lr=1e-6, train_loss=0.08Fold 3: Epoch 19/300:  82%|████████████████████████▋     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.08Fold 3: Epoch 19/300:  82%|███████████████████████▊     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.081Fold 3: Epoch 19/300:  82%|████████████████████████▋     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  82%|█████████████████████████▍     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  82%|███████████████████████     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.0096Fold 3: Epoch 19/300:  82%|████████████████████████▋     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  82%|█████████████████████████▍     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300:  82%|████████████████████████▋     | 1653/2011 [00:22<00:05, 65.96it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:22<00:05, 64.71it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:22<00:05, 64.71it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  83%|███████████████████████▉     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  83%|███████████████████████▉     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.05Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1660/2011 [00:23<00:05, 64.71it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  83%|████████████████████████     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.073Fold 3: Epoch 19/300:  83%|████████████████████████     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  83%|████████████████████████     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.049Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.21Fold 3: Epoch 19/300:  83%|████████████████████████     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.096Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.24Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  83%|████████████████████████▊     | 1667/2011 [00:23<00:05, 64.39it/s, lr=1e-6, train_loss=0.07Fold 3: Epoch 19/300:  83%|█████████████████████████     | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.07Fold 3: Epoch 19/300:  83%|█████████████████████████     | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.26Fold 3: Epoch 19/300:  83%|████████████████████████▏    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  83%|████████████████████████▏    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  83%|████████████████████████▏    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  83%|█████████████████████████     | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  83%|████████████████████████▏    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.079Fold 3: Epoch 19/300:  83%|███████████████████████▎    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.0095Fold 3: Epoch 19/300:  83%|███████████████████████▎    | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.0066Fold 3: Epoch 19/300:  83%|█████████████████████████     | 1676/2011 [00:23<00:04, 69.27it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  84%|█████████████████████████▏    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  84%|█████████████████████████▏    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  84%|█████████████████████████▏    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.06Fold 3: Epoch 19/300:  84%|███████████████████████▍    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.0088Fold 3: Epoch 19/300:  84%|███████████████████████▍    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.0084Fold 3: Epoch 19/300:  84%|█████████████████████████▏    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.27Fold 3: Epoch 19/300:  84%|████████████████████████▎    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.069Fold 3: Epoch 19/300:  84%|███████████████████████▍    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.0052Fold 3: Epoch 19/300:  84%|████████████████████████▎    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  84%|████████████████████████▎    | 1685/2011 [00:23<00:04, 73.07it/s, lr=1e-6, train_loss=0.076Fold 3: Epoch 19/300:  84%|████████████████████████▍    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.076Fold 3: Epoch 19/300:  84%|████████████████████████▍    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  84%|████████████████████████▍    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  84%|█████████████████████████▎    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  84%|███████████████████████▌    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.0092Fold 3: Epoch 19/300:  84%|█████████████████████████▎    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  84%|████████████████████████▍    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  84%|████████████████████████▍    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  84%|███████████████████████▌    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.0086Fold 3: Epoch 19/300:  84%|█████████████████████████▎    | 1694/2011 [00:23<00:04, 75.92it/s, lr=1e-6, train_loss=0.06Fold 3: Epoch 19/300:  85%|█████████████████████████▍    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.06Fold 3: Epoch 19/300:  85%|█████████████████████████▍    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.25Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.098Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  85%|███████████████████████▋    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.0094Fold 3: Epoch 19/300:  85%|████████████████████████▌    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  85%|███████████████████████▋    | 1703/2011 [00:23<00:03, 78.08it/s, lr=1e-6, train_loss=0.0068Fold 3: Epoch 19/300:  85%|███████████████████████▊    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.0068Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.056Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  85%|█████████████████████████▌    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.026Fold 3: Epoch 19/300:  85%|████████████████████████▋    | 1712/2011 [00:23<00:03, 79.68it/s, lr=1e-6, train_loss=0.077Fold 3: Epoch 19/300:  86%|████████████████████████▊    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.077Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.26Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.26Fold 3: Epoch 19/300:  86%|████████████████████████▊    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  86%|████████████████████████▊    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  86%|█████████████████████████▋    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.25Fold 3: Epoch 19/300:  86%|████████████████████████▊    | 1721/2011 [00:23<00:03, 80.86it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.061Fold 3: Epoch 19/300:  86%|██████████████████████████▋    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.037Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.045Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.037Fold 3: Epoch 19/300:  86%|█████████████████████████▊    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.064Fold 3: Epoch 19/300:  86%|█████████████████████████▊    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.32Fold 3: Epoch 19/300:  86%|████████████████████████▉    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  86%|█████████████████████████▊    | 1730/2011 [00:23<00:03, 81.68it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  86%|█████████████████████████▉    | 1739/2011 [00:23<00:03, 82.25it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:23<00:03, 82.25it/s, lr=1e-6, train_loss=0.098Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:23<00:03, 82.25it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:23<00:03, 82.25it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:23<00:03, 82.25it/s, lr=1e-6, train_loss=0.050Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:24<00:03, 82.25it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  86%|████████████████████████▏   | 1739/2011 [00:24<00:03, 82.25it/s, lr=1e-6, train_loss=0.0036Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:24<00:03, 82.25it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  86%|█████████████████████████    | 1739/2011 [00:24<00:03, 82.25it/s, lr=1e-6, train_loss=0.054Fold 3: Epoch 19/300:  86%|█████████████████████████▉    | 1739/2011 [00:24<00:03, 82.25it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  87%|██████████████████████████    | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  87%|██████████████████████████    | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.086Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  87%|██████████████████████████    | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.022Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  87%|█████████████████████████▏   | 1748/2011 [00:24<00:03, 81.11it/s, lr=1e-6, train_loss=0.067Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.067Fold 3: Epoch 19/300:  87%|██████████████████████████▏   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.053Fold 3: Epoch 19/300:  87%|██████████████████████████▏   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.024Fold 3: Epoch 19/300:  87%|████████████████████████▍   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.0065Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  87%|██████████████████████████▏   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  87%|█████████████████████████▎   | 1757/2011 [00:24<00:03, 74.30it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.062Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  88%|██████████████████████████▎   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  88%|███████████████████████████▏   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  88%|██████████████████████████▎   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.078Fold 3: Epoch 19/300:  88%|█████████████████████████▍   | 1766/2011 [00:24<00:03, 77.07it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  88%|█████████████████████████▌   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  88%|█████████████████████████▌   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  88%|███████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.3Fold 3: Epoch 19/300:  88%|██████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  88%|███████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300:  88%|██████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  88%|██████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.20Fold 3: Epoch 19/300:  88%|████████████████████████▋   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.0052Fold 3: Epoch 19/300:  88%|██████████████████████████▍   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  88%|█████████████████████████▌   | 1776/2011 [00:24<00:02, 81.80it/s, lr=1e-6, train_loss=0.043Fold 3: Epoch 19/300:  89%|█████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.043Fold 3: Epoch 19/300:  89%|█████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  89%|██████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  89%|██████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  89%|█████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.059Fold 3: Epoch 19/300:  89%|█████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.049Fold 3: Epoch 19/300:  89%|██████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  89%|███████████████████████████▌   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  89%|███████████████████████████▌   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  89%|█████████████████████████▋   | 1785/2011 [00:24<00:02, 82.87it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  89%|██████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  89%|██████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  89%|██████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.33Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  89%|████████████████████████▉   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.0071Fold 3: Epoch 19/300:  89%|█████████████████████████▊   | 1794/2011 [00:24<00:02, 80.35it/s, lr=1e-6, train_loss=0.048Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.048Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.046Fold 3: Epoch 19/300:  90%|██████████████████████████▉   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  90%|██████████████████████████▉   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  90%|██████████████████████████▉   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.033Fold 3: Epoch 19/300:  90%|██████████████████████████▉   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.30Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  90%|██████████████████████████▉   | 1803/2011 [00:24<00:02, 79.48it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  90%|███████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.048Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.094Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.025Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.037Fold 3: Epoch 19/300:  90%|██████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  90%|███████████████████████████   | 1811/2011 [00:24<00:02, 78.44it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  90%|███████████████████████████▏  | 1819/2011 [00:24<00:02, 77.15it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  90%|███████████████████████████▏  | 1819/2011 [00:24<00:02, 77.15it/s, lr=1e-6, train_loss=0.19Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:24<00:02, 77.15it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.077Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.047Fold 3: Epoch 19/300:  90%|██████████████████████████▏  | 1819/2011 [00:25<00:02, 77.15it/s, lr=1e-6, train_loss=0.068Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.068Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  91%|███████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.062Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.073Fold 3: Epoch 19/300:  91%|██████████████████████████▎  | 1827/2011 [00:25<00:02, 75.44it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.078Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.069Fold 3: Epoch 19/300:  91%|████████████████████████████▎  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.081Fold 3: Epoch 19/300:  91%|███████████████████████████▎  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  91%|██████████████████████████▍  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.064Fold 3: Epoch 19/300:  91%|███████████████████████████▎  | 1835/2011 [00:25<00:02, 72.04it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  92%|███████████████████████████▍  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  92%|██████████████████████████▌  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.060Fold 3: Epoch 19/300:  92%|███████████████████████████▍  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  92%|██████████████████████████▌  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  92%|███████████████████████████▍  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  92%|██████████████████████████▌  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  92%|██████████████████████████▌  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  92%|██████████████████████████▌  | 1843/2011 [00:25<00:02, 68.91it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.040Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300:  92%|███████████████████████████▌  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.36Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  92%|███████████████████████████▌  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  92%|██████████████████████████▋  | 1850/2011 [00:25<00:02, 66.97it/s, lr=1e-6, train_loss=0.080Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.080Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  92%|███████████████████████████▋  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.013Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.028Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  92%|██████████████████████████▊  | 1857/2011 [00:25<00:02, 66.24it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.034Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.031Fold 3: Epoch 19/300:  93%|███████████████████████████▊  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  93%|█████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.0069Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1864/2011 [00:25<00:02, 65.80it/s, lr=1e-6, train_loss=0.091Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.091Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  93%|███████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  93%|██████████████████████████  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.0066Fold 3: Epoch 19/300:  93%|███████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.33Fold 3: Epoch 19/300:  93%|██████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  93%|███████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.03Fold 3: Epoch 19/300:  93%|███████████████████████████▉  | 1871/2011 [00:25<00:02, 65.38it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  93%|████████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  93%|████████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.51Fold 3: Epoch 19/300:  93%|███████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  93%|████████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.29Fold 3: Epoch 19/300:  93%|███████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.038Fold 3: Epoch 19/300:  93%|████████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.18Fold 3: Epoch 19/300:  93%|███████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.070Fold 3: Epoch 19/300:  93%|███████████████████████████  | 1878/2011 [00:25<00:02, 64.72it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  94%|███████████████████████████▏ | 1885/2011 [00:25<00:01, 64.06it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  94%|██████████████████████████▏ | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.0086Fold 3: Epoch 19/300:  94%|████████████████████████████  | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  94%|████████████████████████████  | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  94%|███████████████████████████▏ | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.055Fold 3: Epoch 19/300:  94%|███████████████████████████▏ | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  94%|████████████████████████████  | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.05Fold 3: Epoch 19/300:  94%|███████████████████████████▏ | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  94%|████████████████████████████  | 1885/2011 [00:26<00:01, 64.06it/s, lr=1e-6, train_loss=0.28Fold 3: Epoch 19/300:  94%|████████████████████████████▏ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.28Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.096Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.066Fold 3: Epoch 19/300:  94%|████████████████████████████▏ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  94%|██████████████████████████████  | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.022Fold 3: Epoch 19/300:  94%|████████████████████████████▏ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  94%|█████████████████████████████▏ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.3Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  94%|███████████████████████████▎ | 1893/2011 [00:26<00:01, 66.58it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  95%|███████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.032Fold 3: Epoch 19/300:  95%|████████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  95%|███████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  95%|███████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.016Fold 3: Epoch 19/300:  95%|███████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  95%|████████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  95%|████████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.28Fold 3: Epoch 19/300:  95%|███████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  95%|████████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  95%|██████████████████████████▍ | 1903/2011 [00:26<00:01, 74.33it/s, lr=1e-6, train_loss=0.0081Fold 3: Epoch 19/300:  95%|██████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.0081Fold 3: Epoch 19/300:  95%|███████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.072Fold 3: Epoch 19/300:  95%|████████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  95%|███████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.041Fold 3: Epoch 19/300:  95%|████████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.05Fold 3: Epoch 19/300:  95%|███████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  95%|███████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.012Fold 3: Epoch 19/300:  95%|████████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.16Fold 3: Epoch 19/300:  95%|███████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.036Fold 3: Epoch 19/300:  95%|██████████████████████████▌ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.0061Fold 3: Epoch 19/300:  95%|█████████████████████████████▍ | 1912/2011 [00:26<00:01, 78.63it/s, lr=1e-6, train_loss=0.4Fold 3: Epoch 19/300:  96%|█████████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.4Fold 3: Epoch 19/300:  96%|████████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  96%|████████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.32Fold 3: Epoch 19/300:  96%|███████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.074Fold 3: Epoch 19/300:  96%|███████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.095Fold 3: Epoch 19/300:  96%|███████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.048Fold 3: Epoch 19/300:  96%|██████████████████████████▊ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.0071Fold 3: Epoch 19/300:  96%|███████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.023Fold 3: Epoch 19/300:  96%|███████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  96%|████████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300:  96%|████████████████████████████▋ | 1922/2011 [00:26<00:01, 83.57it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  96%|████████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  96%|████████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  96%|██████████████████████████▉ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.0040Fold 3: Epoch 19/300:  96%|████████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.41Fold 3: Epoch 19/300:  96%|███████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.063Fold 3: Epoch 19/300:  96%|███████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.089Fold 3: Epoch 19/300:  96%|████████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.06Fold 3: Epoch 19/300:  96%|███████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.026Fold 3: Epoch 19/300:  96%|███████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.098Fold 3: Epoch 19/300:  96%|███████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.054Fold 3: Epoch 19/300:  96%|████████████████████████████▊ | 1932/2011 [00:26<00:00, 87.50it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  97%|████████████████████████████▉ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.019Fold 3: Epoch 19/300:  97%|████████████████████████████▉ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.23Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.020Fold 3: Epoch 19/300:  97%|████████████████████████████▉ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.22Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.043Fold 3: Epoch 19/300:  97%|███████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.0074Fold 3: Epoch 19/300:  97%|████████████████████████████▉ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.014Fold 3: Epoch 19/300:  97%|████████████████████████████ | 1942/2011 [00:26<00:00, 90.39it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  97%|████████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.035Fold 3: Epoch 19/300:  97%|██████████████████████████████ | 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  97%|█████████████████████████████ | 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  97%|█████████████████████████████ | 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  97%|████████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.009Fold 3: Epoch 19/300:  97%|█████████████████████████████ | 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.26Fold 3: Epoch 19/300:  97%|████████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.051Fold 3: Epoch 19/300:  97%|█████████████████████████████ | 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  97%|████████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  97%|███████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.0072Fold 3: Epoch 19/300:  97%|████████████████████████████▏| 1952/2011 [00:26<00:00, 92.42it/s, lr=1e-6, train_loss=0.060Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.060Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.015Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300:  98%|█████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.04Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.073Fold 3: Epoch 19/300:  98%|█████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.01Fold 3: Epoch 19/300:  98%|█████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  98%|████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  98%|█████████████████████████████▎| 1962/2011 [00:26<00:00, 93.90it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  98%|█████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  98%|█████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  98%|████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.027Fold 3: Epoch 19/300:  98%|██████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  98%|████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.057Fold 3: Epoch 19/300:  98%|█████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300:  98%|█████████████████████████████▍| 1972/2011 [00:26<00:00, 94.93it/s, lr=1e-6, train_loss=0.03Fold 3: Epoch 19/300:  98%|████████████████████████████▍| 1972/2011 [00:27<00:00, 94.93it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  98%|████████████████████████████▍| 1972/2011 [00:27<00:00, 94.93it/s, lr=1e-6, train_loss=0.029Fold 3: Epoch 19/300:  98%|████████████████████████████▍| 1972/2011 [00:27<00:00, 94.93it/s, lr=1e-6, train_loss=0.010Fold 3: Epoch 19/300:  98%|█████████████████████████████▍| 1972/2011 [00:27<00:00, 94.93it/s, lr=1e-6, train_loss=0.37Fold 3: Epoch 19/300:  99%|█████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.37Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.082Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.081Fold 3: Epoch 19/300:  99%|█████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.14Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.017Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.021Fold 3: Epoch 19/300:  99%|███████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.0078Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.079Fold 3: Epoch 19/300:  99%|████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.043Fold 3: Epoch 19/300:  99%|██████████████████████████████▌| 1982/2011 [00:27<00:00, 95.60it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  99%|██████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.1Fold 3: Epoch 19/300:  99%|████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.030Fold 3: Epoch 19/300:  99%|█████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.13Fold 3: Epoch 19/300:  99%|█████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.11Fold 3: Epoch 19/300:  99%|█████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  99%|████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.044Fold 3: Epoch 19/300:  99%|████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.097Fold 3: Epoch 19/300:  99%|█████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.12Fold 3: Epoch 19/300:  99%|████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.083Fold 3: Epoch 19/300:  99%|█████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.10Fold 3: Epoch 19/300:  99%|████████████████████████████▋| 1992/2011 [00:27<00:00, 96.13it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.018Fold 3: Epoch 19/300: 100%|█████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.15Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.053Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.085Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.011Fold 3: Epoch 19/300: 100%|██████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.0Fold 3: Epoch 19/300: 100%|█████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.17Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.053Fold 3: Epoch 19/300: 100%|████████████████████████████▊| 2002/2011 [00:27<00:00, 96.47it/s, lr=1e-6, train_loss=0.042Fold 3: Epoch 19/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.58it/s, lr=1e-6, train_loss=0.0427]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 436.30it/s]
Accuracy: 0.9661775677692116
F1 score: 0.9685839685839686
Precision score: 0.962359421620381
Recall score: 0.9748895605673099
Train and validation losses: 0.08888878659190066, 0.0885413004701983
=> Saving checkpoint
Fold 3: Epoch 20/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.51it/s, lr=1e-6, train_loss=0.15]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.92it/s]
Accuracy: 0.9671723451877643
F1 score: 0.9695079695079695
Precision score: 0.9632774845076888
Recall score: 0.9758195768425948
Train and validation losses: 0.08642840899736863, 0.08697623927673884
=> Saving checkpoint
Fold 3: Epoch 21/300: 100%|██████████████████████████| 2011/2011 [00:25<00:00, 79.49it/s, lr=1e-6, train_loss=0.00492]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.39it/s]
Accuracy: 0.9677940810743596
F1 score: 0.9700543415423748
Precision score: 0.9648114075436982
Recall score: 0.9753545687049523
Train and validation losses: 0.08454630058027215, 0.0856659514611961
=> Saving checkpoint
Fold 3: Epoch 22/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 72.12it/s, lr=1e-6, train_loss=0.029]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 418.24it/s]
Accuracy: 0.9682914697836359
F1 score: 0.9706051873198848
Precision score: 0.9625057155921354
Recall score: 0.9788421297372704
Train and validation losses: 0.0829040242756394, 0.08485313979112663
=> Saving checkpoint
Fold 3: Epoch 23/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.35it/s, lr=1e-6, train_loss=0.00871]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.61it/s]
Accuracy: 0.9682914697836359
F1 score: 0.9705372616984402
Precision score: 0.9646302250803859
Recall score: 0.9765170890490583
Train and validation losses: 0.08119385177721114, 0.08347558390041794
=> Saving checkpoint
Fold 3: Epoch 24/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.07it/s, lr=1e-6, train_loss=0.012]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.79it/s]
Accuracy: 0.9687888584929122
F1 score: 0.9709860131776673
Precision score: 0.9655172413793104
Recall score: 0.9765170890490583
Train and validation losses: 0.07985655477579381, 0.08253186541585396
=> Saving checkpoint
Fold 3: Epoch 25/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 67.12it/s, lr=1e-6, train_loss=0.0123]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.41it/s]
Accuracy: 0.9691619000248695
F1 score: 0.971309578898658
Precision score: 0.9666129403638039
Recall score: 0.9760520809114159
Train and validation losses: 0.07866965137361417, 0.0816301946791174
=> Saving checkpoint
Fold 3: Epoch 26/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.59it/s, lr=1e-6, train_loss=0.0102]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.48it/s]
Accuracy: 0.9695349415568266
F1 score: 0.9716007882230208
Precision score: 0.9687933425797504
Recall score: 0.9744245524296675
Train and validation losses: 0.07688013393355951, 0.08091664677680235
=> Saving checkpoint
Fold 3: Epoch 27/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 76.13it/s, lr=1e-6, train_loss=0.0166]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 419.35it/s]
Accuracy: 0.9694105943795076
F1 score: 0.9715935334872979
Precision score: 0.9651296168846065
Recall score: 0.9781446175308068
Train and validation losses: 0.07559005528411025, 0.08028452694980764
=> Saving checkpoint
Fold 3: Epoch 28/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 71.55it/s, lr=1e-6, train_loss=0.00375]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.41it/s]
Accuracy: 0.9696592887341458
F1 score: 0.9717592592592592
Precision score: 0.9675040331873703
Recall score: 0.9760520809114159
Train and validation losses: 0.07449694643049973, 0.07933822821707244
=> Saving checkpoint
Fold 3: Epoch 29/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 68.57it/s, lr=1e-6, train_loss=0.137]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 419.32it/s]
Accuracy: 0.9697836359114648
F1 score: 0.9718587145338737
Precision score: 0.968158744808491
Recall score: 0.9755870727737735
Train and validation losses: 0.07395182094689086, 0.07864756857889295
=> Saving checkpoint
Fold 3: Epoch 30/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 75.49it/s, lr=1e-6, train_loss=0.192]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.61it/s]
Accuracy: 0.9702810246207411
F1 score: 0.9723731360536354
Precision score: 0.9668965517241379
Recall score: 0.9779121134619856
Train and validation losses: 0.07181367806037624, 0.07814769296319951
=> Saving checkpoint
Fold 3: Epoch 31/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.63it/s, lr=1e-6, train_loss=0.0123]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 435.85it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9725662692441255
Precision score: 0.9684186260949746
Recall score: 0.9767495931178796
Train and validation losses: 0.07097237154165045, 0.07748037881762249
=> Saving checkpoint
Fold 3: Epoch 32/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.00it/s, lr=1e-6, train_loss=0.049]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.38it/s]
Accuracy: 0.9710271076846556
F1 score: 0.972972972972973
Precision score: 0.9708333333333333
Recall score: 0.9751220646361312
Train and validation losses: 0.06960065917017921, 0.07684958471141748
=> Saving checkpoint
Fold 3: Epoch 33/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 74.41it/s, lr=1e-6, train_loss=0.00307]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.95it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9726169844020798
Precision score: 0.9666972898484153
Recall score: 0.9786096256684492
Train and validation losses: 0.06887597912583965, 0.07689209316906225
Fold 3: Epoch 34/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.39it/s, lr=1e-6, train_loss=0.0672]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.49it/s]
Accuracy: 0.9712758020392938
F1 score: 0.9732546022924626
Precision score: 0.9693265682656826
Recall score: 0.977214601255522
Train and validation losses: 0.06770382985803343, 0.07578093765343301
=> Saving checkpoint
Fold 3: Epoch 35/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 71.70it/s, lr=1e-6, train_loss=0.00262]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.43it/s]
Accuracy: 0.9714001492166128
F1 score: 0.9733734660801111
Precision score: 0.9693336407655061
Recall score: 0.9774471053243432
Train and validation losses: 0.0661075070190319, 0.0752258162434485
=> Saving checkpoint
Fold 3: Epoch 36/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 74.06it/s, lr=1e-6, train_loss=0.00469]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.33it/s]
Accuracy: 0.9715244963939319
F1 score: 0.9734800231615518
Precision score: 0.9697738809413936
Recall score: 0.977214601255522
Train and validation losses: 0.06509681628971378, 0.0746226309443163
=> Saving checkpoint
Fold 3: Epoch 37/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.65it/s, lr=1e-6, train_loss=0.0137]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.84it/s]
Accuracy: 0.9716488435712509
F1 score: 0.9736111111111111
Precision score: 0.96934777598525
Recall score: 0.9779121134619856
Train and validation losses: 0.06378495518300147, 0.07410354850300871
=> Saving checkpoint
Fold 3: Epoch 38/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.91it/s, lr=1e-6, train_loss=0.0374]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.61it/s]
Accuracy: 0.9715244963939319
F1 score: 0.9734431172445784
Precision score: 0.9710782045349375
Recall score: 0.9758195768425948
Train and validation losses: 0.06266056704894125, 0.07338628433362412
=> Saving checkpoint
Fold 3: Epoch 39/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 73.75it/s, lr=1e-6, train_loss=0.16]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.23it/s]
Accuracy: 0.9723949266351654
F1 score: 0.9742757821552723
Precision score: 0.9711249711249711
Recall score: 0.9774471053243432
Train and validation losses: 0.06143106164214813, 0.0729320328252179
=> Saving checkpoint
Fold 3: Epoch 40/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.25it/s, lr=1e-6, train_loss=0.0192]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 437.78it/s]
Accuracy: 0.9723949266351654
F1 score: 0.9743055555555555
Precision score: 0.970039179534455
Recall score: 0.9786096256684492
Train and validation losses: 0.06060722910531406, 0.07257382885046548
=> Saving checkpoint
Fold 3: Epoch 41/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.59it/s, lr=1e-6, train_loss=0.158]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.53it/s]
Accuracy: 0.9726436209898035
F1 score: 0.9744838784504756
Precision score: 0.9722286507752835
Recall score: 0.9767495931178796
Train and validation losses: 0.05950824502153458, 0.07192784331592678
=> Saving checkpoint
Fold 3: Epoch 42/300: 100%|███████████████████████████| 2011/2011 [00:23<00:00, 85.02it/s, lr=1e-6, train_loss=0.0132]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.14it/s]
Accuracy: 0.9732653568763989
F1 score: 0.9751013317892299
Precision score: 0.9713890170742963
Recall score: 0.9788421297372704
Train and validation losses: 0.05827774124307774, 0.07149864065509001
=> Saving checkpoint
Fold 3: Epoch 43/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 71.99it/s, lr=1e-6, train_loss=0.0269]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 434.14it/s]
Accuracy: 0.9731410096990798
F1 score: 0.9750115687181861
Precision score: 0.9702970297029703
Recall score: 0.9797721460125552
Train and validation losses: 0.056593433382396675, 0.07147085043406355
=> Saving checkpoint
Fold 3: Epoch 44/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 69.31it/s, lr=1e-6, train_loss=0.00246]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.18it/s]
Accuracy: 0.9735140512310371
F1 score: 0.9752928894559796
Precision score: 0.9731481481481481
Recall score: 0.9774471053243432
Train and validation losses: 0.0558919044702871, 0.0705376782667014
=> Saving checkpoint
Fold 3: Epoch 45/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.05it/s, lr=1e-6, train_loss=0.00198]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.14it/s]
Accuracy: 0.9737627455856752
F1 score: 0.9755248811042803
Precision score: 0.9733796296296297
Recall score: 0.9776796093931643
Train and validation losses: 0.054698945474018976, 0.07006924752045098
=> Saving checkpoint
Fold 3: Epoch 46/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.57it/s, lr=1e-6, train_loss=0.00613]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.18it/s]
Accuracy: 0.9740114399403134
F1 score: 0.975784961186421
Precision score: 0.9725173210161663
Recall score: 0.9790746338060916
Train and validation losses: 0.05360794259222064, 0.06983569853084633
=> Saving checkpoint
Fold 3: Epoch 47/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.91it/s, lr=1e-6, train_loss=0.00392]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.65it/s]
Accuracy: 0.9740114399403134
F1 score: 0.9758017830265139
Precision score: 0.9718634686346863
Recall score: 0.9797721460125552
Train and validation losses: 0.052380743649779404, 0.06965648416750536
=> Saving checkpoint
Fold 3: Epoch 48/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 71.66it/s, lr=1e-6, train_loss=0.00245]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.06it/s]
Accuracy: 0.9737627455856752
F1 score: 0.975502147915941
Precision score: 0.9742578849721707
Recall score: 0.9767495931178796
Train and validation losses: 0.05089700141413256, 0.06901210419246723
=> Saving checkpoint
Fold 3: Epoch 49/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.16it/s, lr=1e-6, train_loss=0.00284]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.44it/s]
Accuracy: 0.9738870927629942
F1 score: 0.97563239730796
Precision score: 0.9738244151030808
Recall score: 0.9774471053243432
Train and validation losses: 0.05037946223078943, 0.06868353774206376
=> Saving checkpoint
Fold 3: Epoch 50/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 69.53it/s, lr=1e-6, train_loss=0.355]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 420.30it/s]
Accuracy: 0.9738870927629942
F1 score: 0.9757056918093475
Precision score: 0.970987796454064
Recall score: 0.9804696582190189
Train and validation losses: 0.049411890140437294, 0.06902782929363192
Fold 3: Epoch 51/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.48it/s, lr=1e-6, train_loss=0.00259]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.38it/s]
Accuracy: 0.9746331758269088
F1 score: 0.9763286145277327
Precision score: 0.9745193421357424
Recall score: 0.9781446175308068
Train and validation losses: 0.04831520354970692, 0.06821470955575615
=> Saving checkpoint
Fold 3: Epoch 52/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.54it/s, lr=1e-6, train_loss=0.0842]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 437.12it/s]
Accuracy: 0.9745088286495897
F1 score: 0.976231884057971
Precision score: 0.9736355226641998
Recall score: 0.9788421297372704
Train and validation losses: 0.04706790235069196, 0.06803164795324833
=> Saving checkpoint
Fold 3: Epoch 53/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.62it/s, lr=1e-6, train_loss=0.00695]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 434.07it/s]
Accuracy: 0.9747575230042278
F1 score: 0.976463768115942
Precision score: 0.9738667900092507
Recall score: 0.9790746338060916
Train and validation losses: 0.04644582957510518, 0.06791938127020362
=> Saving checkpoint
Fold 3: Epoch 54/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.67it/s, lr=1e-6, train_loss=0.00785]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.81it/s]
Accuracy: 0.9742601342949515
F1 score: 0.9760388933904387
Precision score: 0.9718764407561088
Recall score: 0.9802371541501976
Train and validation losses: 0.04468241829867023, 0.06824151405342067
Fold 3: Epoch 55/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.48it/s, lr=1e-6, train_loss=0.0396]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.87it/s]
Accuracy: 0.9745088286495897
F1 score: 0.9762429018426237
Precision score: 0.9731977818853974
Recall score: 0.9793071378749129
Train and validation losses: 0.04406608084684112, 0.06772047280432067
=> Saving checkpoint
Fold 3: Epoch 56/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.11it/s, lr=1e-6, train_loss=0.0312]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.38it/s]
Accuracy: 0.9752549117135041
F1 score: 0.976922184854459
Precision score: 0.974548819990745
Recall score: 0.9793071378749129
Train and validation losses: 0.043550710387307734, 0.06747693610035076
=> Saving checkpoint
Fold 3: Epoch 57/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.13it/s, lr=1e-6, train_loss=0.00121]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.37it/s]
Accuracy: 0.9752549117135041
F1 score: 0.9769542559351476
Precision score: 0.9732348869404707
Recall score: 0.98070216228784
Train and validation losses: 0.042901426711213955, 0.06761859770399975
Fold 3: Epoch 58/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.94it/s, lr=1e-6, train_loss=0.0279]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 436.93it/s]
Accuracy: 0.9757523004227804
F1 score: 0.9774122552994324
Precision score: 0.9739150507848569
Recall score: 0.9809346663566613
Train and validation losses: 0.04145950123831312, 0.06741177816057131
=> Saving checkpoint
Fold 3: Epoch 59/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 75.62it/s, lr=1e-6, train_loss=0.00654]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.08it/s]
Accuracy: 0.9753792588908232
F1 score: 0.9770408163265306
Precision score: 0.9745547073791349
Recall score: 0.979539641943734
Train and validation losses: 0.04096353975441196, 0.06729615701822597
=> Saving checkpoint
Fold 3: Epoch 60/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.78it/s, lr=1e-6, train_loss=0.00394]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.94it/s]
Accuracy: 0.9753792588908232
F1 score: 0.9770194986072424
Precision score: 0.9754345307068366
Recall score: 0.9786096256684492
Train and validation losses: 0.039860817306852855, 0.0671023692454653
=> Saving checkpoint
Fold 3: Epoch 61/300: 100%|██████████████████████████| 2011/2011 [00:23<00:00, 86.82it/s, lr=1e-6, train_loss=0.00416]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.43it/s]
Accuracy: 0.9756279532454614
F1 score: 0.9772674553467873
Precision score: 0.9750057856977552
Recall score: 0.979539641943734
Train and validation losses: 0.03937383281977149, 0.06714054321044885
Fold 3: Epoch 62/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.15it/s, lr=1e-6, train_loss=0.0426]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 434.18it/s]
Accuracy: 0.9755036060681422
F1 score: 0.9771647154283065
Precision score: 0.9743411927877947
Recall score: 0.9800046500813764
Train and validation losses: 0.036939288574241495, 0.06729638044549723
Fold 3: Epoch 63/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.36it/s, lr=1e-6, train_loss=0.0122]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 435.56it/s]
Accuracy: 0.9751305645361851
F1 score: 0.9768089053803339
Precision score: 0.974323386537127
Recall score: 0.9793071378749129
Train and validation losses: 0.037057709072777084, 0.06711589932028819
Early stopping at epoch 63
Fold 3: Train losses per epoch: [0.690217508746877, 0.6808680899993275, 0.6626686302658813, 0.6282369147954682, 0.5723054304844938, 0.4747481210382349, 0.31906933826128087, 0.21576850828707722, 0.17217492733071066, 0.14954369796383504, 0.13436134333881142, 0.12301114243596481, 0.11382983802145784, 0.10692454048042005, 0.10171212543988593, 0.09686774655438826, 0.0939712328187962, 0.09149902972982282, 0.08888878659190066, 0.08642840899736863, 0.08454630058027215, 0.0829040242756394, 0.08119385177721114, 0.07985655477579381, 0.07866965137361417, 0.07688013393355951, 0.07559005528411025, 0.07449694643049973, 0.07395182094689086, 0.07181367806037624, 0.07097237154165045, 0.06960065917017921, 0.06887597912583965, 0.06770382985803343, 0.0661075070190319, 0.06509681628971378, 0.06378495518300147, 0.06266056704894125, 0.06143106164214813, 0.06060722910531406, 0.05950824502153458, 0.05827774124307774, 0.056593433382396675, 0.0558919044702871, 0.054698945474018976, 0.05360794259222064, 0.052380743649779404, 0.05089700141413256, 0.05037946223078943, 0.049411890140437294, 0.04831520354970692, 0.04706790235069196, 0.04644582957510518, 0.04468241829867023, 0.04406608084684112, 0.043550710387307734, 0.042901426711213955, 0.04145950123831312, 0.04096353975441196, 0.039860817306852855, 0.03937383281977149, 0.036939288574241495, 0.037057709072777084]
Fold 3: Valid losses per epoch: [0.6839730817802384, 0.6707517374343948, 0.6422670054625327, 0.5952054061899128, 0.5205372277476915, 0.3823203627560769, 0.23863638062067108, 0.18199130957927667, 0.15582904812118878, 0.13952123845888534, 0.12753333131899358, 0.11797830134178429, 0.11044066258341399, 0.10437040053082122, 0.09923289451520394, 0.09550216199022905, 0.09259860274830008, 0.09032387249162477, 0.0885413004701983, 0.08697623927673884, 0.0856659514611961, 0.08485313979112663, 0.08347558390041794, 0.08253186541585396, 0.0816301946791174, 0.08091664677680235, 0.08028452694980764, 0.07933822821707244, 0.07864756857889295, 0.07814769296319951, 0.07748037881762249, 0.07684958471141748, 0.07689209316906225, 0.07578093765343301, 0.0752258162434485, 0.0746226309443163, 0.07410354850300871, 0.07338628433362412, 0.0729320328252179, 0.07257382885046548, 0.07192784331592678, 0.07149864065509001, 0.07147085043406355, 0.0705376782667014, 0.07006924752045098, 0.06983569853084633, 0.06965648416750536, 0.06901210419246723, 0.06868353774206376, 0.06902782929363192, 0.06821470955575615, 0.06803164795324833, 0.06791938127020362, 0.06824151405342067, 0.06772047280432067, 0.06747693610035076, 0.06761859770399975, 0.06741177816057131, 0.06729615701822597, 0.0671023692454653, 0.06714054321044885, 0.06729638044549723, 0.06711589932028819]
Fold 4/5
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 4: Epoch 1/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 69.02it/s, lr=1e-6, train_loss=0.687]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.19it/s]
Accuracy: 0.5354389455359363
F1 score: 0.6970974541916654
Precision score: 0.5351674343333749
Recall score: 0.9995349918623576
Train and validation losses: 0.6907988498899724, 0.6864721104354555
=> Saving checkpoint
Fold 4: Epoch 2/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 68.82it/s, lr=1e-6, train_loss=0.647]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 406.81it/s]
Accuracy: 0.5754787366326785
F1 score: 0.6973404255319149
Precision score: 0.5635477862157903
Recall score: 0.9144385026737968
Train and validation losses: 0.6843391061421948, 0.6781120745846576
=> Saving checkpoint
Fold 4: Epoch 3/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.04it/s, lr=1e-6, train_loss=0.648]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.97it/s]
Accuracy: 0.6565530962447153
F1 score: 0.7072291710833156
Precision score: 0.6499123319696084
Recall score: 0.7756335735875378
Train and validation losses: 0.6727628712924424, 0.6590800355253352
=> Saving checkpoint
Fold 4: Epoch 4/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.31it/s, lr=1e-6, train_loss=0.589]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 410.04it/s]
Accuracy: 0.7373787615021139
F1 score: 0.7443718228031954
Precision score: 0.7763191113355213
Recall score: 0.7149500116252034
Train and validation losses: 0.6485060488092905, 0.624515499201257
=> Saving checkpoint
Fold 4: Epoch 5/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 69.98it/s, lr=1e-6, train_loss=0.575]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 414.58it/s]
Accuracy: 0.7878637154936583
F1 score: 0.7873878364905285
Precision score: 0.8485092667203867
Recall score: 0.7344803534061846
Train and validation losses: 0.6065565649103253, 0.5672974417034248
=> Saving checkpoint
Fold 4: Epoch 6/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 68.63it/s, lr=1e-6, train_loss=0.581]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.21it/s]
Accuracy: 0.8431982094006466
F1 score: 0.844493772351708
Precision score: 0.8991596638655462
Recall score: 0.7960939316438038
Train and validation losses: 0.5375395279094273, 0.4757251305205685
=> Saving checkpoint
Fold 4: Epoch 7/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.98it/s, lr=1e-6, train_loss=0.256]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.97it/s]
Accuracy: 0.917060432728177
F1 score: 0.9238149628783552
Precision score: 0.9079479119892232
Recall score: 0.9402464543129505
Train and validation losses: 0.4217053932049333, 0.3227801205327449
=> Saving checkpoint
Fold 4: Epoch 8/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 71.85it/s, lr=1e-6, train_loss=0.0971]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.07it/s]
Accuracy: 0.9388211887590152
F1 score: 0.9444820582261341
Precision score: 0.9175619381714536
Recall score: 0.9730295280167403
Train and validation losses: 0.2720753399813608, 0.19903195199832527
=> Saving checkpoint
Fold 4: Epoch 9/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.99it/s, lr=1e-6, train_loss=0.272]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.33it/s]
Accuracy: 0.9480228798806267
F1 score: 0.9522831050228311
Precision score: 0.9354115272482619
Recall score: 0.9697744710532434
Train and validation losses: 0.18766054219864067, 0.15425792703068042
=> Saving checkpoint
Fold 4: Epoch 10/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 71.88it/s, lr=1e-6, train_loss=0.17]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.32it/s]
Accuracy: 0.9526237254414325
F1 score: 0.9562923023976139
Precision score: 0.9438405797101449
Recall score: 0.9690769588467798
Train and validation losses: 0.15293191929640965, 0.13300475548900975
=> Saving checkpoint
Fold 4: Epoch 11/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 74.67it/s, lr=1e-6, train_loss=0.0434]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 413.26it/s]
Accuracy: 0.9566028351156429
F1 score: 0.9598435162812105
Precision score: 0.9501138952164009
Recall score: 0.9697744710532434
Train and validation losses: 0.1341585791459069, 0.119927022121032
=> Saving checkpoint
Fold 4: Epoch 12/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 72.17it/s, lr=1e-6, train_loss=0.0104]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.70it/s]
Accuracy: 0.9603332504352151
F1 score: 0.963065879356258
Precision score: 0.9591789667896679
Recall score: 0.966984422227389
Train and validation losses: 0.12161977482892014, 0.11198964883864045
=> Saving checkpoint
Fold 4: Epoch 13/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.33it/s, lr=1e-6, train_loss=0.0208]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.84it/s]
Accuracy: 0.9623228052723203
F1 score: 0.9649183744355679
Precision score: 0.9610239852398524
Recall score: 0.9688444547779587
Train and validation losses: 0.11276941127891729, 0.10560144445160867
=> Saving checkpoint
Fold 4: Epoch 14/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 74.32it/s, lr=1e-6, train_loss=0.0414]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 417.18it/s]
Accuracy: 0.9638149714001493
F1 score: 0.9662608695652174
Precision score: 0.963691026827012
Recall score: 0.9688444547779587
Train and validation losses: 0.10636553532860281, 0.10120764569607128
=> Saving checkpoint
Fold 4: Epoch 15/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 71.96it/s, lr=1e-6, train_loss=0.0149]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.25it/s]
Accuracy: 0.9635662770455111
F1 score: 0.9659658496921826
Precision score: 0.9651810584958217
Recall score: 0.9667519181585678
Train and validation losses: 0.10162534549937008, 0.09848208978094501
=> Saving checkpoint
Fold 4: Epoch 16/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.88it/s, lr=1e-6, train_loss=0.0269]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 417.61it/s]
Accuracy: 0.9636906242228301
F1 score: 0.9660622966062297
Precision score: 0.9658377875900535
Recall score: 0.9662869100209254
Train and validation losses: 0.09704073225016034, 0.09623512210950226
=> Saving checkpoint
Fold 4: Epoch 17/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 74.95it/s, lr=1e-6, train_loss=0.00715]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.10it/s]
Accuracy: 0.9643123601094256
F1 score: 0.9666472980825102
Precision score: 0.9663104089219331
Recall score: 0.966984422227389
Train and validation losses: 0.09407673257994473, 0.09429275313351548
=> Saving checkpoint
Fold 4: Epoch 18/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 72.87it/s, lr=1e-6, train_loss=0.58]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.46it/s]
Accuracy: 0.965182790350659
F1 score: 0.9674645596095747
Precision score: 0.9670150987224158
Recall score: 0.9679144385026738
Train and validation losses: 0.09125942517324823, 0.0928009307247107
=> Saving checkpoint
Fold 4: Epoch 19/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.99it/s, lr=1e-6, train_loss=0.0134]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.96it/s]
Accuracy: 0.9658045262372544
F1 score: 0.9679748456969838
Precision score: 0.9696686887540831
Recall score: 0.9662869100209254
Train and validation losses: 0.08954645336611629, 0.09201098979630361
=> Saving checkpoint
Fold 4: Epoch 20/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.05it/s, lr=1e-6, train_loss=0.0265]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 419.05it/s]
Accuracy: 0.9665506093011689
F1 score: 0.9686443641450052
Precision score: 0.9712482468443198
Recall score: 0.9660544059521041
Train and validation losses: 0.0870224766500159, 0.09101521903898929
=> Saving checkpoint
Fold 4: Epoch 21/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.24it/s, lr=1e-6, train_loss=0.0416]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.29it/s]
Accuracy: 0.9659288734145735
F1 score: 0.968139534883721
Precision score: 0.9683647359851129
Recall score: 0.9679144385026738
Train and validation losses: 0.08568688065810699, 0.08930938043372398
=> Saving checkpoint
Fold 4: Epoch 22/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.03it/s, lr=1e-6, train_loss=0.00615]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 420.15it/s]
Accuracy: 0.966923650833126
F1 score: 0.9689542483660131
Precision score: 0.9728146238575112
Recall score: 0.9651243896768193
Train and validation losses: 0.0831975162022088, 0.0892940636240057
=> Saving checkpoint
Fold 4: Epoch 23/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.06it/s, lr=1e-6, train_loss=0.0861]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.38it/s]
Accuracy: 0.9675453867197215
F1 score: 0.9695839645728936
Precision score: 0.9719626168224299
Recall score: 0.9672169262962101
Train and validation losses: 0.08195139395215695, 0.08787674350695496
=> Saving checkpoint
Fold 4: Epoch 24/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 74.21it/s, lr=1e-6, train_loss=0.00729]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.07it/s]
Accuracy: 0.9676697338970406
F1 score: 0.9696686887540831
Precision score: 0.9730742214937954
Recall score: 0.9662869100209254
Train and validation losses: 0.08076702494985619, 0.08723124630414097
=> Saving checkpoint
Fold 4: Epoch 25/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.58it/s, lr=1e-6, train_loss=0.0161]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.06it/s]
Accuracy: 0.9682914697836359
F1 score: 0.9702693249387898
Precision score: 0.9731057062675398
Recall score: 0.9674494303650314
Train and validation losses: 0.07975338949751959, 0.08613285953067909
=> Saving checkpoint
Fold 4: Epoch 26/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.97it/s, lr=1e-6, train_loss=0.146]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.93it/s]
Accuracy: 0.968540164138274
F1 score: 0.9704956268221574
Precision score: 0.9735610669162377
Recall score: 0.9674494303650314
Train and validation losses: 0.07795299427242962, 0.08538871177122234
=> Saving checkpoint
Fold 4: Epoch 27/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.28it/s, lr=1e-6, train_loss=0.587]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.23it/s]
Accuracy: 0.9686645113155932
F1 score: 0.9705676243868255
Precision score: 0.9751232105139639
Recall score: 0.9660544059521041
Train and validation losses: 0.07666316239764402, 0.08520653221254454
=> Saving checkpoint
Fold 4: Epoch 28/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.16it/s, lr=1e-6, train_loss=0.397]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.49it/s]
Accuracy: 0.9689132056702313
F1 score: 0.9708420807091206
Precision score: 0.9740229347062953
Recall score: 0.9676819344338526
Train and validation losses: 0.07454947657093094, 0.08372073116523415
=> Saving checkpoint
Fold 4: Epoch 29/300: 100%|████████████████████████████| 2011/2011 [00:25<00:00, 78.87it/s, lr=1e-6, train_loss=0.491]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.93it/s]
Accuracy: 0.9695349415568266
F1 score: 0.9714418929945215
Precision score: 0.9740532959326789
Recall score: 0.9688444547779587
Train and validation losses: 0.07358843026017471, 0.0826952205318217
=> Saving checkpoint
Fold 4: Epoch 30/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.80it/s, lr=1e-6, train_loss=0.437]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.48it/s]
Accuracy: 0.9691619000248695
F1 score: 0.9710483306093859
Precision score: 0.9751465416178194
Recall score: 0.966984422227389
Train and validation losses: 0.07242976763463532, 0.08267582071645123
=> Saving checkpoint
Fold 4: Epoch 31/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 69.99it/s, lr=1e-6, train_loss=0.00421]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.42it/s]
Accuracy: 0.9690375528475503
F1 score: 0.9709078163336838
Precision score: 0.9758102395490841
Recall score: 0.9660544059521041
Train and validation losses: 0.07102898257175087, 0.08231882741498885
=> Saving checkpoint
Fold 4: Epoch 32/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.57it/s, lr=1e-6, train_loss=0.388]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.03it/s]
Accuracy: 0.9696592887341458
F1 score: 0.9715219421101774
Precision score: 0.9753925474572299
Recall score: 0.9676819344338526
Train and validation losses: 0.06972680248279349, 0.08076467268515164
=> Saving checkpoint
Fold 4: Epoch 33/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.33it/s, lr=1e-6, train_loss=0.00572]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.70it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9723937099592312
Precision score: 0.9743230625583567
Recall score: 0.9704719832597071
Train and validation losses: 0.06826297371867768, 0.0795664621968837
=> Saving checkpoint
Fold 4: Epoch 34/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.84it/s, lr=1e-6, train_loss=0.0018]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.65it/s]
Accuracy: 0.9709027605073365
F1 score: 0.9727526781555659
Precision score: 0.9743410310240261
Recall score: 0.9711694954661707
Train and validation losses: 0.0670932422385471, 0.07882808342439013
=> Saving checkpoint
Fold 4: Epoch 35/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.82it/s, lr=1e-6, train_loss=0.00654]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.98it/s]
Accuracy: 0.9707784133300174
F1 score: 0.9726139144621839
Precision score: 0.975
Recall score: 0.9702394791908858
Train and validation losses: 0.06547826790087127, 0.07824460492574908
=> Saving checkpoint
Fold 4: Epoch 36/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 75.50it/s, lr=1e-6, train_loss=0.00884]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.06it/s]
Accuracy: 0.9707784133300174
F1 score: 0.9725819624314549
Precision score: 0.9761124121779859
Recall score: 0.9690769588467798
Train and validation losses: 0.06449957279484277, 0.07762249946551653
=> Saving checkpoint
Fold 4: Epoch 37/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.19it/s, lr=1e-6, train_loss=0.00593]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.52it/s]
Accuracy: 0.9715244963939319
F1 score: 0.9732882304910766
Precision score: 0.9765917602996255
Recall score: 0.9700069751220647
Train and validation losses: 0.06351939259198403, 0.07686832226455494
=> Saving checkpoint
Fold 4: Epoch 38/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.00it/s, lr=1e-6, train_loss=0.024]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.25it/s]
Accuracy: 0.9716488435712509
F1 score: 0.9734389561975769
Precision score: 0.9754844734998832
Recall score: 0.9714019995349918
Train and validation losses: 0.06160395892485393, 0.07576603781168996
=> Saving checkpoint
Fold 4: Epoch 39/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.28it/s, lr=1e-6, train_loss=0.00811]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.49it/s]
Accuracy: 0.9718975379258891
F1 score: 0.9736719478098789
Precision score: 0.9757179547046463
Recall score: 0.9716345036038131
Train and validation losses: 0.06078992341893986, 0.07496743334020316
=> Saving checkpoint
Fold 4: Epoch 40/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.11it/s, lr=1e-6, train_loss=0.311]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.23it/s]
Accuracy: 0.9723949266351654
F1 score: 0.9741017265515632
Precision score: 0.9775228283774292
Recall score: 0.9707044873285282
Train and validation losses: 0.05934140836517361, 0.0746819493270555
=> Saving checkpoint
Fold 4: Epoch 41/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 69.97it/s, lr=1e-6, train_loss=0.135]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.47it/s]
Accuracy: 0.9728923153444416
F1 score: 0.9746157428970657
Precision score: 0.9762071378586424
Recall score: 0.9730295280167403
Train and validation losses: 0.057997908189368064, 0.07348995789988282
=> Saving checkpoint
Fold 4: Epoch 42/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.09it/s, lr=1e-6, train_loss=0.0107]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.63it/s]
Accuracy: 0.9730166625217608
F1 score: 0.9747115720778464
Precision score: 0.9771028037383177
Recall score: 0.9723320158102767
Train and validation losses: 0.05753008243227253, 0.07281948611599431
=> Saving checkpoint
Fold 4: Epoch 43/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.42it/s, lr=1e-6, train_loss=0.0315]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.87it/s]
Accuracy: 0.9728923153444416
F1 score: 0.9745742943783532
Precision score: 0.977767376550433
Recall score: 0.9714019995349918
Train and validation losses: 0.05634295847596881, 0.07237625600322044
=> Saving checkpoint
Fold 4: Epoch 44/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 69.11it/s, lr=1e-6, train_loss=0.00705]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.93it/s]
Accuracy: 0.9735140512310371
F1 score: 0.975195062303482
Precision score: 0.9769015398973402
Recall score: 0.9734945361543828
Train and validation losses: 0.054739969581366045, 0.07136198980215322
=> Saving checkpoint
Fold 4: Epoch 45/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 67.99it/s, lr=1e-6, train_loss=0.041]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.75it/s]
Accuracy: 0.9741357871176324
F1 score: 0.9757009345794393
Precision score: 0.9805118572434844
Recall score: 0.9709369913973495
Train and validation losses: 0.053994402627695455, 0.0714765085723477
Fold 4: Epoch 46/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.74it/s, lr=1e-6, train_loss=0.00176]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 410.79it/s]
Accuracy: 0.9740114399403134
F1 score: 0.9756608827297077
Precision score: 0.9773681754549697
Recall score: 0.9739595442920251
Train and validation losses: 0.05239453416040759, 0.07009143264530038
=> Saving checkpoint
Fold 4: Epoch 47/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.76it/s, lr=1e-6, train_loss=0.0648]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 405.32it/s]
Accuracy: 0.975006217358866
F1 score: 0.9765488274413721
Precision score: 0.9800936768149883
Recall score: 0.9730295280167403
Train and validation losses: 0.05140539473623722, 0.06986215458599625
=> Saving checkpoint
Fold 4: Epoch 48/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 72.80it/s, lr=1e-6, train_loss=0.0722]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.93it/s]
Accuracy: 0.9747575230042278
F1 score: 0.9763596133690462
Precision score: 0.9780681287914139
Recall score: 0.9746570564984888
Train and validation losses: 0.04990467366857745, 0.06907818797780442
=> Saving checkpoint
Fold 4: Epoch 49/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.02it/s, lr=1e-6, train_loss=0.00742]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 418.15it/s]
Accuracy: 0.9748818701815469
F1 score: 0.9764404012129695
Precision score: 0.9796395974725017
Recall score: 0.9732620320855615
Train and validation losses: 0.049238127843060725, 0.06861961110857007
=> Saving checkpoint
Fold 4: Epoch 50/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 72.94it/s, lr=1e-6, train_loss=0.0696]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.89it/s]
Accuracy: 0.9756279532454614
F1 score: 0.9771401912759505
Precision score: 0.9803416803182775
Recall score: 0.9739595442920251
Train and validation losses: 0.04823786355165463, 0.06812968239476108
=> Saving checkpoint
Fold 4: Epoch 51/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 70.24it/s, lr=1e-6, train_loss=0.00337]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.70it/s]
Accuracy: 0.9762496891320567
F1 score: 0.9776999416228839
Precision score: 0.9819418386491557
Recall score: 0.9734945361543828
Train and validation losses: 0.04761031344658007, 0.06785323893606003
=> Saving checkpoint
Fold 4: Epoch 52/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.25it/s, lr=1e-6, train_loss=0.158]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 399.79it/s]
Accuracy: 0.9762496891320567
F1 score: 0.9777311414247406
Precision score: 0.9805893358278766
Recall score: 0.9748895605673099
Train and validation losses: 0.046806052779763324, 0.06726444196224464
=> Saving checkpoint
Fold 4: Epoch 53/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 69.54it/s, lr=1e-6, train_loss=0.00686]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.50it/s]
Accuracy: 0.9769957721959711
F1 score: 0.9784507862550961
Precision score: 0.9803921568627451
Recall score: 0.9765170890490583
Train and validation losses: 0.04575638076061131, 0.06682476348710703
=> Saving checkpoint
Fold 4: Epoch 54/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.53it/s, lr=1e-6, train_loss=0.119]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.86it/s]
Accuracy: 0.9771201193732902
F1 score: 0.9785497785031476
Precision score: 0.9812953004442366
Recall score: 0.9758195768425948
Train and validation losses: 0.044437352294442234, 0.06662709796562824
=> Saving checkpoint
Fold 4: Epoch 55/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 67.23it/s, lr=1e-6, train_loss=0.00757]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.37it/s]
Accuracy: 0.9776175080825665
F1 score: 0.9789817842129845
Precision score: 0.9833450621627962
Recall score: 0.9746570564984888
Train and validation losses: 0.043862398632145375, 0.06670733698376197
Fold 4: Epoch 56/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.15it/s, lr=1e-6, train_loss=0.0117]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.72it/s]
Accuracy: 0.9768714250186521
F1 score: 0.978326730365882
Precision score: 0.9806120065405279
Recall score: 0.9760520809114159
Train and validation losses: 0.043350939862828376, 0.06605116197125149
=> Saving checkpoint
Fold 4: Epoch 57/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 69.10it/s, lr=1e-6, train_loss=0.0321]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.12it/s]
Accuracy: 0.9774931609052474
F1 score: 0.9788970502506704
Precision score: 0.9817586529466792
Recall score: 0.9760520809114159
Train and validation losses: 0.04221762253919409, 0.06594019611046703
=> Saving checkpoint
Fold 4: Epoch 58/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.90it/s, lr=1e-6, train_loss=0.0014]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.53it/s]
Accuracy: 0.976747077841333
F1 score: 0.9782279660030271
Precision score: 0.9797108208955224
Recall score: 0.9767495931178796
Train and validation losses: 0.04122479018005128, 0.0655609077178488
=> Saving checkpoint
Fold 4: Epoch 59/300: 100%|████████████████████████████| 2011/2011 [00:26<00:00, 76.93it/s, lr=1e-6, train_loss=0.107]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.08it/s]
Accuracy: 0.9769957721959711
F1 score: 0.9784507862550961
Precision score: 0.9803921568627451
Recall score: 0.9765170890490583
Train and validation losses: 0.04096819811551204, 0.06535718683593131
=> Saving checkpoint
Fold 4: Epoch 60/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.67it/s, lr=1e-6, train_loss=0.00813]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.57it/s]
Accuracy: 0.9768714250186521
F1 score: 0.9783418723800652
Precision score: 0.9799393515278749
Recall score: 0.9767495931178796
Train and validation losses: 0.03932774096402265, 0.06520677210668668
=> Saving checkpoint
Fold 4: Epoch 61/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 69.09it/s, lr=1e-6, train_loss=0.00908]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.86it/s]
Accuracy: 0.9768714250186521
F1 score: 0.9783368273934312
Precision score: 0.9801633605600933
Recall score: 0.9765170890490583
Train and validation losses: 0.039473301448116206, 0.06511768186904646
=> Saving checkpoint
Fold 4: Epoch 62/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.18it/s, lr=1e-6, train_loss=0.00371]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.55it/s]
Accuracy: 0.9771201193732902
F1 score: 0.97856477166822
Precision score: 0.9806210600046696
Recall score: 0.9765170890490583
Train and validation losses: 0.0384092489510431, 0.06507520716548036
=> Saving checkpoint
Fold 4: Epoch 63/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 74.53it/s, lr=1e-6, train_loss=0.00282]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 416.88it/s]
Accuracy: 0.9772444665506093
F1 score: 0.978683750728014
Precision score: 0.98062558356676
Recall score: 0.9767495931178796
Train and validation losses: 0.0376950562443446, 0.06496780643331732
=> Saving checkpoint
Fold 4: Epoch 64/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.76it/s, lr=1e-6, train_loss=0.0198]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.31it/s]
Accuracy: 0.9774931609052474
F1 score: 0.9789461440037223
Precision score: 0.9795158286778398
Recall score: 0.978377121599628
Train and validation losses: 0.03711744255359606, 0.0649151794840841
=> Saving checkpoint
Fold 4: Epoch 65/300: 100%|██████████████████████████| 2011/2011 [00:30<00:00, 66.06it/s, lr=1e-6, train_loss=0.00204]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.61it/s]
Accuracy: 0.9773688137279284
F1 score: 0.9787977632805219
Precision score: 0.9808545412094326
Recall score: 0.9767495931178796
Train and validation losses: 0.036701532298925255, 0.06479606247155476
=> Saving checkpoint
Fold 4: Epoch 66/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 69.00it/s, lr=1e-6, train_loss=0.0101]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.72it/s]
Accuracy: 0.9769957721959711
F1 score: 0.9784908731542844
Precision score: 0.9786046511627907
Recall score: 0.978377121599628
Train and validation losses: 0.03547444083193694, 0.06484914426059994
Fold 4: Epoch 67/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 67.77it/s, lr=1e-6, train_loss=0.0197]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 412.78it/s]
Accuracy: 0.9776175080825665
F1 score: 0.9790405216581276
Precision score: 0.9806391415908561
Recall score: 0.9774471053243432
Train and validation losses: 0.034990573632763006, 0.06470710113182873
=> Saving checkpoint
Fold 4: Epoch 68/300: 100%|██████████████████████████| 2011/2011 [00:25<00:00, 80.18it/s, lr=1e-6, train_loss=0.00956]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.15it/s]
Accuracy: 0.9774931609052474
F1 score: 0.978931439878943
Precision score: 0.9801864801864801
Recall score: 0.9776796093931643
Train and validation losses: 0.034436877192449485, 0.06476805805617242
Fold 4: Epoch 69/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.97it/s, lr=1e-6, train_loss=0.00359]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.18it/s]
Accuracy: 0.9777418552598856
F1 score: 0.9791350973306913
Precision score: 0.9817671809256662
Recall score: 0.9765170890490583
Train and validation losses: 0.033474193029450684, 0.06485636975888392
Fold 4: Epoch 70/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.32it/s, lr=1e-6, train_loss=0.0281]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.78it/s]
Accuracy: 0.9773688137279284
F1 score: 0.9787878787878788
Precision score: 0.9813040430007011
Recall score: 0.9762845849802372
Train and validation losses: 0.03283355890643189, 0.06479258988981615
Early stopping at epoch 70
Fold 4: Train losses per epoch: [0.6907988498899724, 0.6843391061421948, 0.6727628712924424, 0.6485060488092905, 0.6065565649103253, 0.5375395279094273, 0.4217053932049333, 0.2720753399813608, 0.18766054219864067, 0.15293191929640965, 0.1341585791459069, 0.12161977482892014, 0.11276941127891729, 0.10636553532860281, 0.10162534549937008, 0.09704073225016034, 0.09407673257994473, 0.09125942517324823, 0.08954645336611629, 0.0870224766500159, 0.08568688065810699, 0.0831975162022088, 0.08195139395215695, 0.08076702494985619, 0.07975338949751959, 0.07795299427242962, 0.07666316239764402, 0.07454947657093094, 0.07358843026017471, 0.07242976763463532, 0.07102898257175087, 0.06972680248279349, 0.06826297371867768, 0.0670932422385471, 0.06547826790087127, 0.06449957279484277, 0.06351939259198403, 0.06160395892485393, 0.06078992341893986, 0.05934140836517361, 0.057997908189368064, 0.05753008243227253, 0.05634295847596881, 0.054739969581366045, 0.053994402627695455, 0.05239453416040759, 0.05140539473623722, 0.04990467366857745, 0.049238127843060725, 0.04823786355165463, 0.04761031344658007, 0.046806052779763324, 0.04575638076061131, 0.044437352294442234, 0.043862398632145375, 0.043350939862828376, 0.04221762253919409, 0.04122479018005128, 0.04096819811551204, 0.03932774096402265, 0.039473301448116206, 0.0384092489510431, 0.0376950562443446, 0.03711744255359606, 0.036701532298925255, 0.03547444083193694, 0.034990573632763006, 0.034436877192449485, 0.033474193029450684, 0.03283355890643189]
Fold 4: Valid losses per epoch: [0.6864721104354555, 0.6781120745846576, 0.6590800355253352, 0.624515499201257, 0.5672974417034248, 0.4757251305205685, 0.3227801205327449, 0.19903195199832527, 0.15425792703068042, 0.13300475548900975, 0.119927022121032, 0.11198964883864045, 0.10560144445160867, 0.10120764569607128, 0.09848208978094501, 0.09623512210950226, 0.09429275313351548, 0.0928009307247107, 0.09201098979630361, 0.09101521903898929, 0.08930938043372398, 0.0892940636240057, 0.08787674350695496, 0.08723124630414097, 0.08613285953067909, 0.08538871177122234, 0.08520653221254454, 0.08372073116523415, 0.0826952205318217, 0.08267582071645123, 0.08231882741498885, 0.08076467268515164, 0.0795664621968837, 0.07882808342439013, 0.07824460492574908, 0.07762249946551653, 0.07686832226455494, 0.07576603781168996, 0.07496743334020316, 0.0746819493270555, 0.07348995789988282, 0.07281948611599431, 0.07237625600322044, 0.07136198980215322, 0.0714765085723477, 0.07009143264530038, 0.06986215458599625, 0.06907818797780442, 0.06861961110857007, 0.06812968239476108, 0.06785323893606003, 0.06726444196224464, 0.06682476348710703, 0.06662709796562824, 0.06670733698376197, 0.06605116197125149, 0.06594019611046703, 0.0655609077178488, 0.06535718683593131, 0.06520677210668668, 0.06511768186904646, 0.06507520716548036, 0.06496780643331732, 0.0649151794840841, 0.06479606247155476, 0.06484914426059994, 0.06470710113182873, 0.06476805805617242, 0.06485636975888392, 0.06479258988981615]
Fold 5/5
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Fold 5: Epoch 1/300: 100%|█████████████████████████████| 2011/2011 [00:27<00:00, 74.38it/s, lr=1e-6, train_loss=0.696]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 417.29it/s]
Accuracy: 0.534817209649341
F1 score: 0.6969132301709471
Precision score: 0.534817209649341
Recall score: 1.0
Train and validation losses: 0.6903690883083049, 0.6855553129084304
=> Saving checkpoint
Fold 5: Epoch 2/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.51it/s, lr=1e-6, train_loss=0.683]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.03it/s]
Accuracy: 0.5920169112161154
F1 score: 0.7027271903596992
Precision score: 0.5757125890736342
Recall score: 0.9016507788886305
Train and validation losses: 0.6823961885635798, 0.6752241559578458
=> Saving checkpoint
Fold 5: Epoch 3/300: 100%|█████████████████████████████| 2011/2011 [00:30<00:00, 65.69it/s, lr=1e-6, train_loss=0.645]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.36it/s]
Accuracy: 0.6724695349415568
F1 score: 0.7098479841374752
Precision score: 0.6744818924010886
Recall score: 0.7491281097419205
Train and validation losses: 0.6669300139572774, 0.651597155846848
=> Saving checkpoint
Fold 5: Epoch 4/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 69.71it/s, lr=1e-6, train_loss=0.592]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.11it/s]
Accuracy: 0.7472021885103208
F1 score: 0.7413815036254929
Precision score: 0.8185393258426966
Recall score: 0.6775168565449895
Train and validation losses: 0.6356024215732387, 0.6089193554332195
=> Saving checkpoint
Fold 5: Epoch 5/300: 100%|█████████████████████████████| 2011/2011 [00:29<00:00, 67.70it/s, lr=1e-6, train_loss=0.645]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 419.16it/s]
Accuracy: 0.8004227804028848
F1 score: 0.7962939459322249
Precision score: 0.8767467859139184
Recall score: 0.7293652638921181
Train and validation losses: 0.5825350664552321, 0.5366730101065892
=> Saving checkpoint
Fold 5: Epoch 6/300: 100%|█████████████████████████████| 2011/2011 [00:26<00:00, 76.82it/s, lr=1e-6, train_loss=0.435]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.41it/s]
Accuracy: 0.8796319323551356
F1 score: 0.8873632767046776
Precision score: 0.8881900768693222
Recall score: 0.8865380144152523
Train and validation losses: 0.4871270100552309, 0.40092349117603265
=> Saving checkpoint
Fold 5: Epoch 7/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.61it/s, lr=1e-6, train_loss=0.332]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.14it/s]
Accuracy: 0.9220343198209401
F1 score: 0.9304029304029304
Precision score: 0.8901869158878505
Recall score: 0.9744245524296675
Train and validation losses: 0.3354750228337184, 0.2488195234928169
=> Saving checkpoint
Fold 5: Epoch 8/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 70.24it/s, lr=1e-6, train_loss=0.063]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.95it/s]
Accuracy: 0.9404377020641631
F1 score: 0.9458940472156331
Precision score: 0.9198154657293497
Recall score: 0.9734945361543828
Train and validation losses: 0.22156355289018967, 0.180193579139162
=> Saving checkpoint
Fold 5: Epoch 9/300: 100%|█████████████████████████████| 2011/2011 [00:28<00:00, 71.70it/s, lr=1e-6, train_loss=0.209]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.41it/s]
Accuracy: 0.9466550609301169
F1 score: 0.9511111111111111
Precision score: 0.93272239606616
Recall score: 0.9702394791908858
Train and validation losses: 0.17093000316011525, 0.14997592832426546
=> Saving checkpoint
Fold 5: Epoch 10/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.01it/s, lr=1e-6, train_loss=0.108]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.74it/s]
Accuracy: 0.951877642377518
F1 score: 0.9558067831449126
Precision score: 0.9391831238779175
Recall score: 0.9730295280167403
Train and validation losses: 0.14530705123739654, 0.13220897503197193
=> Saving checkpoint
Fold 5: Epoch 11/300: 100%|████████████████████████████| 2011/2011 [00:29<00:00, 69.11it/s, lr=1e-6, train_loss=0.111]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.53it/s]
Accuracy: 0.9562297935836856
F1 score: 0.95973461450469
Precision score: 0.9446070704796217
Recall score: 0.9753545687049523
Train and validation losses: 0.13057041180855908, 0.12082558580550178
=> Saving checkpoint
Fold 5: Epoch 12/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 67.22it/s, lr=1e-6, train_loss=0.0381]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.94it/s]
Accuracy: 0.9589654314847053
F1 score: 0.9620776832911975
Precision score: 0.9511474664848898
Recall score: 0.9732620320855615
Train and validation losses: 0.11869381585360789, 0.11321828451385318
=> Saving checkpoint
Fold 5: Epoch 13/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 70.55it/s, lr=1e-6, train_loss=0.353]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.46it/s]
Accuracy: 0.9602089032578961
F1 score: 0.9631760644418872
Precision score: 0.9535201640464799
Recall score: 0.9730295280167403
Train and validation losses: 0.11092913118878787, 0.10715611550723671
=> Saving checkpoint
Fold 5: Epoch 14/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.53it/s, lr=1e-6, train_loss=0.192]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.17it/s]
Accuracy: 0.9615767222084058
F1 score: 0.9644214162348878
Precision score: 0.9552919708029197
Recall score: 0.9737270402232039
Train and validation losses: 0.10557919133649996, 0.10244849999666689
=> Saving checkpoint
Fold 5: Epoch 15/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.34it/s, lr=1e-6, train_loss=0.0504]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.72it/s]
Accuracy: 0.9630688883362347
F1 score: 0.9657478952831277
Precision score: 0.9581235697940503
Recall score: 0.9734945361543828
Train and validation losses: 0.10047892908890343, 0.09911819874210873
=> Saving checkpoint
Fold 5: Epoch 16/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 71.97it/s, lr=1e-6, train_loss=0.0111]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.57it/s]
Accuracy: 0.9640636657547874
F1 score: 0.9667089045040894
Precision score: 0.9579908675799087
Recall score: 0.9755870727737735
Train and validation losses: 0.09733172686708501, 0.09608699185042374
=> Saving checkpoint
Fold 5: Epoch 17/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 74.46it/s, lr=1e-6, train_loss=0.0271]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.75it/s]
Accuracy: 0.9646854016413827
F1 score: 0.9672584735992622
Precision score: 0.9592956780242397
Recall score: 0.9753545687049523
Train and validation losses: 0.09447579474912235, 0.09385510584409858
=> Saving checkpoint
Fold 5: Epoch 18/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 76.09it/s, lr=1e-6, train_loss=0.0311]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 417.87it/s]
Accuracy: 0.9653071375279781
F1 score: 0.967727009832273
Precision score: 0.9629373848987108
Recall score: 0.9725645198790979
Train and validation losses: 0.09115748037850417, 0.09233456575052505
=> Saving checkpoint
Fold 5: Epoch 19/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.11it/s, lr=1e-6, train_loss=0.0238]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.79it/s]
Accuracy: 0.9658045262372544
F1 score: 0.9682117674257311
Precision score: 0.9627586206896551
Recall score: 0.9737270402232039
Train and validation losses: 0.08920342848781627, 0.09043785019418517
=> Saving checkpoint
Fold 5: Epoch 20/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 69.20it/s, lr=1e-6, train_loss=0.0137]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.77it/s]
Accuracy: 0.966799303655807
F1 score: 0.9691150954308849
Precision score: 0.9643186003683242
Recall score: 0.9739595442920251
Train and validation losses: 0.0876505850634363, 0.08914077060832225
=> Saving checkpoint
Fold 5: Epoch 21/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 71.95it/s, lr=1e-6, train_loss=0.0133]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.71it/s]
Accuracy: 0.9674210395424024
F1 score: 0.9696548529071114
Precision score: 0.9660743134087237
Recall score: 0.9732620320855615
Train and validation losses: 0.08600491483930604, 0.08802851379819392
=> Saving checkpoint
Fold 5: Epoch 22/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.41it/s, lr=1e-6, train_loss=0.0492]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.60it/s]
Accuracy: 0.9676697338970406
F1 score: 0.9699074074074074
Precision score: 0.9656602903894906
Recall score: 0.9741920483608463
Train and validation losses: 0.08416369297388387, 0.08667893062931695
=> Saving checkpoint
Fold 5: Epoch 23/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.58it/s, lr=1e-6, train_loss=0.0163]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 425.56it/s]
Accuracy: 0.9677940810743596
F1 score: 0.9699849345231197
Precision score: 0.9669593345656192
Recall score: 0.9730295280167403
Train and validation losses: 0.08266769295124396, 0.0857675466503648
=> Saving checkpoint
Fold 5: Epoch 24/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.30it/s, lr=1e-6, train_loss=0.0123]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.54it/s]
Accuracy: 0.968415816960955
F1 score: 0.9706018518518519
Precision score: 0.9663516939386956
Recall score: 0.9748895605673099
Train and validation losses: 0.08245144665094434, 0.08458059044692769
=> Saving checkpoint
Fold 5: Epoch 25/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.48it/s, lr=1e-6, train_loss=0.0165]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 415.60it/s]
Accuracy: 0.968540164138274
F1 score: 0.9707345286292655
Precision score: 0.9659300184162063
Recall score: 0.9755870727737735
Train and validation losses: 0.08002524701209228, 0.08364181939066272
=> Saving checkpoint
Fold 5: Epoch 26/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.40it/s, lr=1e-6, train_loss=0.0194]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.03it/s]
Accuracy: 0.9680427754289977
F1 score: 0.9702028985507246
Precision score: 0.967622571692877
Recall score: 0.9727970239479191
Train and validation losses: 0.07885805871867918, 0.08316952876573536
=> Saving checkpoint
Fold 5: Epoch 27/300: 100%|██████████████████████████| 2011/2011 [00:25<00:00, 77.36it/s, lr=1e-6, train_loss=0.00975]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 414.60it/s]
Accuracy: 0.968415816960955
F1 score: 0.9705609643022717
Precision score: 0.9676450196440952
Recall score: 0.9734945361543828
Train and validation losses: 0.07754966797557679, 0.08218770319800528
=> Saving checkpoint
Fold 5: Epoch 28/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.03it/s, lr=1e-6, train_loss=0.058]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 406.08it/s]
Accuracy: 0.9682914697836359
F1 score: 0.9704621800069501
Precision score: 0.9669898430286242
Recall score: 0.9739595442920251
Train and validation losses: 0.07647173529412563, 0.08134581747480574
=> Saving checkpoint
Fold 5: Epoch 29/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.06it/s, lr=1e-6, train_loss=0.0542]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 417.73it/s]
Accuracy: 0.9689132056702313
F1 score: 0.9709369913973495
Precision score: 0.9709369913973495
Recall score: 0.9709369913973495
Train and validation losses: 0.07513924080413993, 0.08116415131996361
=> Saving checkpoint
Fold 5: Epoch 30/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.51it/s, lr=1e-6, train_loss=0.0598]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.57it/s]
Accuracy: 0.9687888584929122
F1 score: 0.9709658762290341
Precision score: 0.9661602209944752
Recall score: 0.9758195768425948
Train and validation losses: 0.07422412926766953, 0.07976595289120172
=> Saving checkpoint
Fold 5: Epoch 31/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 76.23it/s, lr=1e-6, train_loss=0.0249]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.61it/s]
Accuracy: 0.9691619000248695
F1 score: 0.971256374594344
Precision score: 0.9683383406517218
Recall score: 0.9741920483608463
Train and validation losses: 0.07270770101837651, 0.07921337126869946
=> Saving checkpoint
Fold 5: Epoch 32/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.55it/s, lr=1e-6, train_loss=0.0395]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.10it/s]
Accuracy: 0.9691619000248695
F1 score: 0.9712830013895322
Precision score: 0.9674740484429065
Recall score: 0.9751220646361312
Train and validation losses: 0.07188167946039427, 0.07847799090682446
=> Saving checkpoint
Fold 5: Epoch 33/300: 100%|███████████████████████████| 2011/2011 [00:25<00:00, 79.29it/s, lr=1e-6, train_loss=0.0446]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.66it/s]
Accuracy: 0.9694105943795076
F1 score: 0.971461716937355
Precision score: 0.9694373697615188
Recall score: 0.9734945361543828
Train and validation losses: 0.06996641236338635, 0.07803802262106632
=> Saving checkpoint
Fold 5: Epoch 34/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 69.82it/s, lr=1e-6, train_loss=0.0117]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.51it/s]
Accuracy: 0.9694105943795076
F1 score: 0.9714947856315179
Precision score: 0.9683529683529684
Recall score: 0.9746570564984888
Train and validation losses: 0.06955968631231858, 0.07728924899048192
=> Saving checkpoint
Fold 5: Epoch 35/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 71.07it/s, lr=1e-6, train_loss=0.0141]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.28it/s]
Accuracy: 0.9699079830887839
F1 score: 0.9718670076726342
Precision score: 0.9718670076726342
Recall score: 0.9718670076726342
Train and validation losses: 0.06853282530822159, 0.07716808284523621
=> Saving checkpoint
Fold 5: Epoch 36/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.39it/s, lr=1e-6, train_loss=0.0216]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.20it/s]
Accuracy: 0.9694105943795076
F1 score: 0.971461716937355
Precision score: 0.9694373697615188
Recall score: 0.9734945361543828
Train and validation losses: 0.06759510199448593, 0.07613387442342974
=> Saving checkpoint
Fold 5: Epoch 37/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.11it/s, lr=1e-6, train_loss=0.0191]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.65it/s]
Accuracy: 0.9704053717980602
F1 score: 0.9724791859389454
Precision score: 0.96733379342075
Recall score: 0.9776796093931643
Train and validation losses: 0.0661557071107291, 0.07548283526667432
=> Saving checkpoint
Fold 5: Epoch 38/300: 100%|███████████████████████████| 2011/2011 [00:30<00:00, 66.96it/s, lr=1e-6, train_loss=0.0131]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.54it/s]
Accuracy: 0.9697836359114648
F1 score: 0.9718260869565217
Precision score: 0.9692414431082331
Recall score: 0.9744245524296675
Train and validation losses: 0.06484002496168195, 0.07488098090920027
=> Saving checkpoint
Fold 5: Epoch 39/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.74it/s, lr=1e-6, train_loss=0.00366]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.80it/s]
Accuracy: 0.9697836359114648
F1 score: 0.971839147062232
Precision score: 0.9688077634011091
Recall score: 0.9748895605673099
Train and validation losses: 0.06344701274276597, 0.07431729315482932
=> Saving checkpoint
Fold 5: Epoch 40/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.71it/s, lr=1e-6, train_loss=0.0417]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 424.68it/s]
Accuracy: 0.9700323302661029
F1 score: 0.972070923629621
Precision score: 0.9690388170055453
Recall score: 0.9751220646361312
Train and validation losses: 0.06280098206834606, 0.07381875770503032
=> Saving checkpoint
Fold 5: Epoch 41/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 74.83it/s, lr=1e-6, train_loss=0.00359]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.37it/s]
Accuracy: 0.970156677443422
F1 score: 0.9721448467966574
Precision score: 0.9705677867902666
Recall score: 0.9737270402232039
Train and validation losses: 0.062224857712211756, 0.0734126603565962
=> Saving checkpoint
Fold 5: Epoch 42/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 74.44it/s, lr=1e-6, train_loss=0.136]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.88it/s]
Accuracy: 0.9700323302661029
F1 score: 0.9720579710144928
Precision score: 0.969472710453284
Recall score: 0.9746570564984888
Train and validation losses: 0.060307737107210144, 0.07289744075862173
=> Saving checkpoint
Fold 5: Epoch 43/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 73.09it/s, lr=1e-6, train_loss=0.124]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.30it/s]
Accuracy: 0.9699079830887839
F1 score: 0.9719127205199629
Precision score: 0.9703360370799536
Recall score: 0.9734945361543828
Train and validation losses: 0.059292528283766556, 0.07260165345567143
=> Saving checkpoint
Fold 5: Epoch 44/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 71.93it/s, lr=1e-6, train_loss=0.00458]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 422.29it/s]
Accuracy: 0.9699079830887839
F1 score: 0.9719192388025064
Precision score: 0.9701181375955524
Recall score: 0.9737270402232039
Train and validation losses: 0.0585608069876057, 0.07209470540863253
=> Saving checkpoint
Fold 5: Epoch 45/300: 100%|██████████████████████████| 2011/2011 [00:25<00:00, 77.50it/s, lr=1e-6, train_loss=0.00067]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 435.72it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9725662692441255
Precision score: 0.9684186260949746
Recall score: 0.9767495931178796
Train and validation losses: 0.0575684939818165, 0.07165656978112625
=> Saving checkpoint
Fold 5: Epoch 46/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 77.00it/s, lr=1e-6, train_loss=0.0215]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.60it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9725535610885929
Precision score: 0.9688509460083065
Recall score: 0.9762845849802372
Train and validation losses: 0.05611182496503685, 0.07123554624255124
=> Saving checkpoint
Fold 5: Epoch 47/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.69it/s, lr=1e-6, train_loss=0.0225]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 427.97it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9725026105116603
Precision score: 0.9705882352941176
Recall score: 0.9744245524296675
Train and validation losses: 0.05536053611794815, 0.07095575830739484
=> Saving checkpoint
Fold 5: Epoch 48/300: 100%|████████████████████████████| 2011/2011 [00:28<00:00, 71.18it/s, lr=1e-6, train_loss=0.751]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.37it/s]
Accuracy: 0.9705297189753792
F1 score: 0.9725472025946947
Precision score: 0.969067405355494
Recall score: 0.9760520809114159
Train and validation losses: 0.054207855959324244, 0.07054001302365769
=> Saving checkpoint
Fold 5: Epoch 49/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 67.93it/s, lr=1e-6, train_loss=0.00333]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.32it/s]
Accuracy: 0.9707784133300174
F1 score: 0.9727599397241219
Precision score: 0.9699491447064262
Recall score: 0.9755870727737735
Train and validation losses: 0.05313955474302079, 0.07023474090421576
=> Saving checkpoint
Fold 5: Epoch 50/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 73.22it/s, lr=1e-6, train_loss=0.0121]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.58it/s]
Accuracy: 0.9706540661526983
F1 score: 0.9726662033819782
Precision score: 0.9690745441957074
Recall score: 0.9762845849802372
Train and validation losses: 0.051735945452330706, 0.0700310446969076
=> Saving checkpoint
Fold 5: Epoch 51/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 75.70it/s, lr=1e-6, train_loss=0.00695]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.43it/s]
Accuracy: 0.9707784133300174
F1 score: 0.9727725640134399
Precision score: 0.9695150115473441
Recall score: 0.9760520809114159
Train and validation losses: 0.050818301168054365, 0.0697294971946151
=> Saving checkpoint
Fold 5: Epoch 52/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 76.75it/s, lr=1e-6, train_loss=0.0044]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.73it/s]
Accuracy: 0.9711514548619746
F1 score: 0.9730920900023197
Precision score: 0.9708400833140477
Recall score: 0.9753545687049523
Train and validation losses: 0.05029236075367287, 0.06938642268666209
=> Saving checkpoint
Fold 5: Epoch 53/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 72.41it/s, lr=1e-6, train_loss=0.0296]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.10it/s]
Accuracy: 0.9709027605073365
F1 score: 0.9728664192949907
Precision score: 0.9703909322229933
Recall score: 0.9753545687049523
Train and validation losses: 0.049022829566838746, 0.0691368944794134
=> Saving checkpoint
Fold 5: Epoch 54/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 69.56it/s, lr=1e-6, train_loss=0.00339]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.98it/s]
Accuracy: 0.9711514548619746
F1 score: 0.9730983302411874
Precision score: 0.9706222530650012
Recall score: 0.9755870727737735
Train and validation losses: 0.04842958723449378, 0.06889884136191331
=> Saving checkpoint
Fold 5: Epoch 55/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.82it/s, lr=1e-6, train_loss=0.0074]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.75it/s]
Accuracy: 0.9714001492166128
F1 score: 0.9733178654292344
Precision score: 0.9712896503820329
Recall score: 0.9753545687049523
Train and validation losses: 0.04743561122480438, 0.06866770030537882
=> Saving checkpoint
Fold 5: Epoch 56/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 72.34it/s, lr=1e-6, train_loss=0.00388]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 433.14it/s]
Accuracy: 0.9721462322805272
F1 score: 0.9740680713128039
Precision score: 0.9700253631542541
Recall score: 0.9781446175308068
Train and validation losses: 0.046154433079146094, 0.06882830097992251
Fold 5: Epoch 57/300: 100%|██████████████████████████| 2011/2011 [00:27<00:00, 73.30it/s, lr=1e-6, train_loss=0.00176]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.58it/s]
Accuracy: 0.9718975379258891
F1 score: 0.9737940630797773
Precision score: 0.9713162155910248
Recall score: 0.9762845849802372
Train and validation losses: 0.04539346651801416, 0.06837039772248929
=> Saving checkpoint
Fold 5: Epoch 58/300: 100%|███████████████████████████| 2011/2011 [00:28<00:00, 70.40it/s, lr=1e-6, train_loss=0.0202]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 431.53it/s]
Accuracy: 0.9726436209898035
F1 score: 0.9744720352750058
Precision score: 0.9726662033819782
Recall score: 0.9762845849802372
Train and validation losses: 0.0441324596342708, 0.0681943317456819
=> Saving checkpoint
Fold 5: Epoch 59/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 74.72it/s, lr=1e-6, train_loss=0.00609]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 421.57it/s]
Accuracy: 0.9728923153444416
F1 score: 0.974721706864564
Precision score: 0.9722414989590562
Recall score: 0.977214601255522
Train and validation losses: 0.04341687609723847, 0.0680518116301831
=> Saving checkpoint
Fold 5: Epoch 60/300: 100%|███████████████████████████| 2011/2011 [00:27<00:00, 72.33it/s, lr=1e-6, train_loss=0.0303]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 423.74it/s]
Accuracy: 0.9733897040537179
F1 score: 0.9752257467006251
Precision score: 0.9711782338021674
Recall score: 0.9793071378749129
Train and validation losses: 0.04257148406105945, 0.06829331344680696
Fold 5: Epoch 61/300: 100%|██████████████████████████| 2011/2011 [00:28<00:00, 71.17it/s, lr=1e-6, train_loss=0.00117]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 426.51it/s]
Accuracy: 0.9732653568763989
F1 score: 0.9750551108017171
Precision score: 0.9731357109773043
Recall score: 0.9769820971867008
Train and validation losses: 0.041506630003973075, 0.06791034319091341
=> Saving checkpoint
Fold 5: Epoch 62/300: 100%|███████████████████████████| 2011/2011 [00:26<00:00, 75.84it/s, lr=1e-6, train_loss=0.0225]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 434.52it/s]
Accuracy: 0.9737627455856752
F1 score: 0.9755475721404566
Precision score: 0.9725046210720887
Recall score: 0.9786096256684492
Train and validation losses: 0.04039472195332335, 0.06803879758050789
Fold 5: Epoch 63/300: 100%|██████████████████████████| 2011/2011 [00:26<00:00, 75.46it/s, lr=1e-6, train_loss=0.00038]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 432.32it/s]
Accuracy: 0.9730166625217608
F1 score: 0.9747879632856977
Precision score: 0.9742220157919182
Recall score: 0.9753545687049523
Train and validation losses: 0.03981073708641936, 0.06789705229437795
=> Saving checkpoint
Fold 5: Epoch 64/300: 100%|██████████████████████████| 2011/2011 [00:29<00:00, 68.97it/s, lr=1e-6, train_loss=0.00144]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 430.30it/s]
Accuracy: 0.9737627455856752
F1 score: 0.9755135197864686
Precision score: 0.9738183503243745
Recall score: 0.977214601255522
Train and validation losses: 0.03871826811128957, 0.06790584524934667
Fold 5: Epoch 65/300: 100%|███████████████████████████| 2011/2011 [00:29<00:00, 68.29it/s, lr=1e-6, train_loss=0.0074]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 428.45it/s]
Accuracy: 0.9745088286495897
F1 score: 0.9762978379003353
Precision score: 0.9710211591536339
Recall score: 0.9816321785631249
Train and validation losses: 0.03808222059044693, 0.06910947673592094
Fold 5: Epoch 66/300: 100%|████████████████████████████| 2011/2011 [00:27<00:00, 71.91it/s, lr=1e-6, train_loss=0.002]
Evaluating valid dataset of 8042 instances: 100%|██████████████████████████████████| 503/503 [00:01<00:00, 429.35it/s]
Accuracy: 0.9741357871176324
F1 score: 0.975886853698122
Precision score: 0.9731791907514451
Recall score: 0.9786096256684492
Train and validation losses: 0.03776090302524455, 0.06807753849406838
Early stopping at epoch 66
Fold 5: Train losses per epoch: [0.6903690883083049, 0.6823961885635798, 0.6669300139572774, 0.6356024215732387, 0.5825350664552321, 0.4871270100552309, 0.3354750228337184, 0.22156355289018967, 0.17093000316011525, 0.14530705123739654, 0.13057041180855908, 0.11869381585360789, 0.11092913118878787, 0.10557919133649996, 0.10047892908890343, 0.09733172686708501, 0.09447579474912235, 0.09115748037850417, 0.08920342848781627, 0.0876505850634363, 0.08600491483930604, 0.08416369297388387, 0.08266769295124396, 0.08245144665094434, 0.08002524701209228, 0.07885805871867918, 0.07754966797557679, 0.07647173529412563, 0.07513924080413993, 0.07422412926766953, 0.07270770101837651, 0.07188167946039427, 0.06996641236338635, 0.06955968631231858, 0.06853282530822159, 0.06759510199448593, 0.0661557071107291, 0.06484002496168195, 0.06344701274276597, 0.06280098206834606, 0.062224857712211756, 0.060307737107210144, 0.059292528283766556, 0.0585608069876057, 0.0575684939818165, 0.05611182496503685, 0.05536053611794815, 0.054207855959324244, 0.05313955474302079, 0.051735945452330706, 0.050818301168054365, 0.05029236075367287, 0.049022829566838746, 0.04842958723449378, 0.04743561122480438, 0.046154433079146094, 0.04539346651801416, 0.0441324596342708, 0.04341687609723847, 0.04257148406105945, 0.041506630003973075, 0.04039472195332335, 0.03981073708641936, 0.03871826811128957, 0.03808222059044693, 0.03776090302524455]
Fold 5: Valid losses per epoch: [0.6855553129084304, 0.6752241559578458, 0.651597155846848, 0.6089193554332195, 0.5366730101065892, 0.40092349117603265, 0.2488195234928169, 0.180193579139162, 0.14997592832426546, 0.13220897503197193, 0.12082558580550178, 0.11321828451385318, 0.10715611550723671, 0.10244849999666689, 0.09911819874210873, 0.09608699185042374, 0.09385510584409858, 0.09233456575052505, 0.09043785019418517, 0.08914077060832225, 0.08802851379819392, 0.08667893062931695, 0.0857675466503648, 0.08458059044692769, 0.08364181939066272, 0.08316952876573536, 0.08218770319800528, 0.08134581747480574, 0.08116415131996361, 0.07976595289120172, 0.07921337126869946, 0.07847799090682446, 0.07803802262106632, 0.07728924899048192, 0.07716808284523621, 0.07613387442342974, 0.07548283526667432, 0.07488098090920027, 0.07431729315482932, 0.07381875770503032, 0.0734126603565962, 0.07289744075862173, 0.07260165345567143, 0.07209470540863253, 0.07165656978112625, 0.07123554624255124, 0.07095575830739484, 0.07054001302365769, 0.07023474090421576, 0.0700310446969076, 0.0697294971946151, 0.06938642268666209, 0.0691368944794134, 0.06889884136191331, 0.06866770030537882, 0.06882830097992251, 0.06837039772248929, 0.0681943317456819, 0.0680518116301831, 0.06829331344680696, 0.06791034319091341, 0.06803879758050789, 0.06789705229437795, 0.06790584524934667, 0.06910947673592094, 0.06807753849406838]
/home/SGF.EDUBEAR.NET/kh597s/research/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
=> Loading checkpoint
Fold 1: Evaluating test dataset of 10052 instances: 100%|██████████████████████████| 629/629 [00:04<00:00, 148.08it/s]
Fold 1: Accuracy: 0.9768205332272185
Fold 1: F1 score: 0.978323564982789
Fold 1: Precision score: 0.9785966871394007
Fold 1: Recall score: 0.9780505952380952
=> Loading checkpoint
Fold 2: Evaluating test dataset of 10052 instances: 100%|██████████████████████████| 629/629 [00:04<00:00, 147.10it/s]
Fold 2: Accuracy: 0.9755272582570633
Fold 2: F1 score: 0.9770992366412213
Fold 2: Precision score: 0.9780096906448006
Fold 2: Recall score: 0.9761904761904762
=> Loading checkpoint
Fold 3: Evaluating test dataset of 10052 instances: 100%|██████████████████████████| 629/629 [00:04<00:00, 145.94it/s]
Fold 3: Accuracy: 0.9737365698368484
Fold 3: F1 score: 0.9754189944134078
Fold 3: Precision score: 0.9765100671140939
Fold 3: Recall score: 0.9743303571428571
=> Loading checkpoint
Fold 4: Evaluating test dataset of 10052 instances: 100%|██████████████████████████| 629/629 [00:04<00:00, 145.44it/s]
Fold 4: Accuracy: 0.9771189812972543
Fold 4: F1 score: 0.9786205614426473
Fold 4: Precision score: 0.9780750650315868
Fold 4: Recall score: 0.9791666666666666
=> Loading checkpoint
Fold 5: Evaluating test dataset of 10052 instances: 100%|██████████████████████████| 629/629 [00:04<00:00, 141.56it/s]
Fold 5: Accuracy: 0.9735376044568245
Fold 5: F1 score: 0.9752050708426547
Fold 5: Precision score: 0.9773916292974589
Fold 5: Recall score: 0.9730282738095238
Cross Validation Accuracy: 0.9758257063270991
Cross Validation F1-score: 0.9773974513998698
Cross Validation Precision: 0.9774883720930233
Cross Validation Recall: 0.9773065476190477
Trained BiGRU with Attention model in 10332.4318 seconds
